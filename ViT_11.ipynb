{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import glob\n",
    "from itertools import chain\n",
    "import os\n",
    "import random\n",
    "import cv2  # Assuming you have OpenCV installed\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import cv2\n",
    "from linformer import Linformer\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.notebook import tqdm\n",
    "import itertools\n",
    "\n",
    "from vit_pytorch.efficient import ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Parameters\n",
    "dataset = \"C:\\\\Study\\\\OJT\\\\Dataset\\\\UCF11_updated_mpg\"          # Dataset path\n",
    "dataset2 = \"C:\\\\Study\\\\OJT\\\\Dataset_Extraction\\\\UCF11\"                   # Dataset2 path\n",
    "train_path = \"C:\\\\Study\\\\OJT\\\\Dataset_Extraction\\\\UCF11Train\"             # Training path\n",
    "test_path = \"C:\\\\Study\\\\OJT\\\\Dataset_Extraction\\\\UCF11Test\"             # Testing path\n",
    "no_of_frames = 1650                     # Total number of frames to be extracted\n",
    "categories = os.listdir(dataset)        # Name of each class/category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A folder C:\\Study\\OJT\\Dataset_Extraction\\UCF11 already exists...\n"
     ]
    }
   ],
   "source": [
    "# Creating dataset directory\n",
    "try:\n",
    "    os.mkdir(dataset2)\n",
    "    print(\"Folder {} created...\".format(dataset2))\n",
    "except:\n",
    "    print(\"A folder {} already exists...\".format(dataset2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A folder C:\\Study\\OJT\\Dataset_Extraction\\UCF11Train already exists...\n"
     ]
    }
   ],
   "source": [
    "# Creating training_set directory\n",
    "try:\n",
    "    os.mkdir(train_path)\n",
    "    print(\"Folder {} created...\".format(train_path))\n",
    "except:\n",
    "    print(\"A folder {} already exists...\".format(train_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A folder C:\\Study\\OJT\\Dataset_Extraction\\UCF11Test already exists...\n"
     ]
    }
   ],
   "source": [
    "# Creating testing_set directory\n",
    "try:\n",
    "    os.mkdir(test_path)\n",
    "    print(\"Folder {} created...\".format(test_path))\n",
    "except:\n",
    "    print(\"A folder {} already exists...\".format(test_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A folder already exists, named basketball...\n",
      "A folder already exists, named biking...\n",
      "A folder already exists, named diving...\n",
      "A folder already exists, named golf_swing...\n",
      "A folder already exists, named horse_riding...\n",
      "A folder already exists, named soccer_juggling...\n",
      "A folder already exists, named swing...\n",
      "A folder already exists, named tennis_swing...\n",
      "A folder already exists, named trampoline_jumping...\n",
      "A folder already exists, named volleyball_spiking...\n",
      "A folder already exists, named walking...\n"
     ]
    }
   ],
   "source": [
    "# Creating same directories for dataset2/ that are already present in the dataset directory\n",
    "for category in categories:\n",
    "    try:\n",
    "        os.mkdir(os.path.join(dataset2, category))\n",
    "        print(\"Folder {} created...\".format(category))\n",
    "    except:\n",
    "        print(\"A folder already exists, named {}...\".format(category, dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A folder already exists, named basketball...\n",
      "A folder already exists, named biking...\n",
      "A folder already exists, named diving...\n",
      "A folder already exists, named golf_swing...\n",
      "A folder already exists, named horse_riding...\n",
      "A folder already exists, named soccer_juggling...\n",
      "A folder already exists, named swing...\n",
      "A folder already exists, named tennis_swing...\n",
      "A folder already exists, named trampoline_jumping...\n",
      "A folder already exists, named volleyball_spiking...\n",
      "A folder already exists, named walking...\n"
     ]
    }
   ],
   "source": [
    "for category in categories:\n",
    "    try:\n",
    "        os.mkdir(os.path.join(train_path, category))\n",
    "        print(\"Folder {} created...\".format(category))\n",
    "    except:\n",
    "        print(\"A folder already exists, named {}...\".format(category, train_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A folder already exists, named basketball...\n",
      "A folder already exists, named biking...\n",
      "A folder already exists, named diving...\n",
      "A folder already exists, named golf_swing...\n",
      "A folder already exists, named horse_riding...\n",
      "A folder already exists, named soccer_juggling...\n",
      "A folder already exists, named swing...\n",
      "A folder already exists, named tennis_swing...\n",
      "A folder already exists, named trampoline_jumping...\n",
      "A folder already exists, named volleyball_spiking...\n",
      "A folder already exists, named walking...\n"
     ]
    }
   ],
   "source": [
    "# Creating same directories for testing_set/ that are already present in the dataset directory\n",
    "for category in categories:\n",
    "    try:\n",
    "        os.mkdir(os.path.join(test_path, category))\n",
    "        print(\"Folder {} created...\".format(category))\n",
    "    except:\n",
    "        print(\"A folder already exists, named {}...\".format(category, test_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25158866a2814e0fae4c2e30282dd748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Combining multiple videos into single video file\n",
    "for category in tqdm(categories):\n",
    "    videofiles = glob.glob(os.path.join(dataset, category, \"**/*.mpg\"), recursive=True)\n",
    "    if videofiles:\n",
    "        cap = cv2.VideoCapture(videofiles[0])\n",
    "    else:\n",
    "        print(\"No video files found in {}/{}\".format(dataset, category))\n",
    "    video_index = 0\n",
    "    cap = cv2.VideoCapture(videofiles[0])    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "    # fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "    out = cv2.VideoWriter(\"{}/{}/{}.mpg\".format(dataset2, category, category), fourcc, 25, (320, 240))\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if frame is None:\n",
    "            video_index += 1\n",
    "            if video_index >= len(videofiles):\n",
    "                break\n",
    "            else:\n",
    "                cap = cv2.VideoCapture(videofiles[ video_index ])\n",
    "                ret, frame = cap.read()\n",
    "                out.write(frame)\n",
    "        else:\n",
    "            out.write(frame)\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbc840972b56413493f303f72037fafb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18247, 30554, 26591, 22528, 34639, 42460, 25130, 25016, 21291, 12076, 25593]\n"
     ]
    }
   ],
   "source": [
    "# Saving total no. of frames of each classes/categories into an array\n",
    "total_frames = []\n",
    "for category in tqdm(categories):\n",
    "    cap = cv2.VideoCapture(dataset2 + \"/\" + category + \"/\" + category + \".mpg\")\n",
    "    length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    total_frames.append(length)\n",
    "    cap.release()\n",
    "    \n",
    "print(total_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a6df61efd5c4e6587ea5d469a55307a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extracting one frame per five frame from the Videos\n",
    "for category in tqdm(categories):\n",
    "    count = 0    \n",
    "    a = glob.glob(dataset2 + '/' + category + '/' + category +'.mpg')\n",
    "    for i in range(len(a)):\n",
    "        cap = cv2.VideoCapture(a[i])\n",
    "        frameRate = cap.get(5)\n",
    "        while(cap.isOpened()):\n",
    "            frameId = cap.get(1)\n",
    "            ret, frame = cap.read()\n",
    "            if (ret != True):\n",
    "                break\n",
    "            if (frameId % math.floor(frameRate) == 0):\n",
    "                cv2.imwrite(train_path + '/' + category + '/{}_{}.jpg'.format(category, count), frame)\n",
    "                count += 1\n",
    "        cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae68ee1505f6479fbcc3ee6e93a76679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Moving 150 random images from training_set into testing_set\n",
    "for category in tqdm(categories):\n",
    "    sub_file = [file for file in glob.glob(train_path +'/'+ category +'/'+ \"*.jpg\")]\n",
    "    test_files = random.sample(sub_file, 25)\n",
    "    for test_file in test_files:\n",
    "        img = cv2.imread(test_file)\n",
    "        os.remove(test_file)\n",
    "        test_filename = os.path.basename(test_file)\n",
    "        cv2.imwrite(test_path +'/' + category + '/' + test_filename , img)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficient_transformer = Linformer(\n",
    "    dim=128,\n",
    "    seq_len=49+1,  # 7x7 patches + 1 cls-token\n",
    "    depth=12,\n",
    "    heads=8,\n",
    "    k=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ViT(\n",
    "    dim=128,\n",
    "    image_size=224,\n",
    "    patch_size=32,\n",
    "    num_classes=11,\n",
    "    transformer=efficient_transformer,\n",
    "    channels=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "lr = 0.001\n",
    "gamma = 0.7\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "# scheduler\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformation for loading and preprocessing images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),  # You can adjust the crop size as needed\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom dataset for the entire training set\n",
    "full_dataset = ImageFolder(train_path, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and validation sets\n",
    "train_size = int(0.8 * len(full_dataset))  # 80% for training\n",
    "val_size = len(full_dataset) - train_size  # 20% for validation\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom datasets for training and test\n",
    "train_dataset = ImageFolder(train_path, transform=transform)\n",
    "test_dataset = ImageFolder(test_path, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders for training and test sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables for early stopping\n",
    "best_val_accuracy = 0.0\n",
    "patience = 10  # Number of epochs to wait for improvement\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 10/174, Loss: 2.2322, Training Accuracy: 25.78%\n",
      "Epoch 1, Batch 20/174, Loss: 2.1763, Training Accuracy: 23.28%\n",
      "Epoch 1, Batch 30/174, Loss: 1.9882, Training Accuracy: 25.26%\n",
      "Epoch 1, Batch 40/174, Loss: 1.9207, Training Accuracy: 27.38%\n",
      "Epoch 1, Batch 50/174, Loss: 1.7644, Training Accuracy: 29.19%\n",
      "Epoch 1, Batch 60/174, Loss: 1.6437, Training Accuracy: 31.74%\n",
      "Epoch 1, Batch 70/174, Loss: 1.3805, Training Accuracy: 34.84%\n",
      "Epoch 1, Batch 80/174, Loss: 1.2276, Training Accuracy: 37.77%\n",
      "Epoch 1, Batch 90/174, Loss: 1.1877, Training Accuracy: 40.30%\n",
      "Epoch 1, Batch 100/174, Loss: 1.0411, Training Accuracy: 42.80%\n",
      "Epoch 1, Batch 110/174, Loss: 1.0043, Training Accuracy: 45.00%\n",
      "Epoch 1, Batch 120/174, Loss: 1.0570, Training Accuracy: 46.64%\n",
      "Epoch 1, Batch 130/174, Loss: 0.9661, Training Accuracy: 48.33%\n",
      "Epoch 1, Batch 140/174, Loss: 0.9383, Training Accuracy: 49.88%\n",
      "Epoch 1, Batch 150/174, Loss: 0.9387, Training Accuracy: 51.17%\n",
      "Epoch 1, Batch 160/174, Loss: 0.8445, Training Accuracy: 52.46%\n",
      "Epoch 1, Batch 170/174, Loss: 0.8142, Training Accuracy: 53.72%\n",
      "Epoch 1, Training Accuracy: 54.09%, Validation Accuracy: 79.28%\n",
      "Epoch 2, Batch 10/174, Loss: 0.6782, Training Accuracy: 80.94%\n",
      "Epoch 2, Batch 20/174, Loss: 0.5611, Training Accuracy: 81.02%\n",
      "Epoch 2, Batch 30/174, Loss: 0.5556, Training Accuracy: 81.15%\n",
      "Epoch 2, Batch 40/174, Loss: 0.5840, Training Accuracy: 81.09%\n",
      "Epoch 2, Batch 50/174, Loss: 0.4981, Training Accuracy: 81.81%\n",
      "Epoch 2, Batch 60/174, Loss: 0.5816, Training Accuracy: 81.72%\n",
      "Epoch 2, Batch 70/174, Loss: 0.5491, Training Accuracy: 81.63%\n",
      "Epoch 2, Batch 80/174, Loss: 0.4631, Training Accuracy: 82.01%\n",
      "Epoch 2, Batch 90/174, Loss: 0.5347, Training Accuracy: 82.17%\n",
      "Epoch 2, Batch 100/174, Loss: 0.5432, Training Accuracy: 82.06%\n",
      "Epoch 2, Batch 110/174, Loss: 0.4748, Training Accuracy: 82.29%\n",
      "Epoch 2, Batch 120/174, Loss: 0.4626, Training Accuracy: 82.55%\n",
      "Epoch 2, Batch 130/174, Loss: 0.4667, Training Accuracy: 82.64%\n",
      "Epoch 2, Batch 140/174, Loss: 0.4972, Training Accuracy: 82.71%\n",
      "Epoch 2, Batch 150/174, Loss: 0.4943, Training Accuracy: 82.76%\n",
      "Epoch 2, Batch 160/174, Loss: 0.4361, Training Accuracy: 82.86%\n",
      "Epoch 2, Batch 170/174, Loss: 0.4391, Training Accuracy: 82.99%\n",
      "Epoch 2, Training Accuracy: 83.12%, Validation Accuracy: 89.05%\n",
      "Epoch 3, Batch 10/174, Loss: 0.2918, Training Accuracy: 90.47%\n",
      "Epoch 3, Batch 20/174, Loss: 0.2693, Training Accuracy: 91.02%\n",
      "Epoch 3, Batch 30/174, Loss: 0.2188, Training Accuracy: 91.67%\n",
      "Epoch 3, Batch 40/174, Loss: 0.2465, Training Accuracy: 92.07%\n",
      "Epoch 3, Batch 50/174, Loss: 0.2284, Training Accuracy: 92.38%\n",
      "Epoch 3, Batch 60/174, Loss: 0.1823, Training Accuracy: 92.81%\n",
      "Epoch 3, Batch 70/174, Loss: 0.1814, Training Accuracy: 93.04%\n",
      "Epoch 3, Batch 80/174, Loss: 0.1831, Training Accuracy: 93.20%\n",
      "Epoch 3, Batch 90/174, Loss: 0.2230, Training Accuracy: 93.16%\n",
      "Epoch 3, Batch 100/174, Loss: 0.2340, Training Accuracy: 93.09%\n",
      "Epoch 3, Batch 110/174, Loss: 0.2717, Training Accuracy: 92.90%\n",
      "Epoch 3, Batch 120/174, Loss: 0.2469, Training Accuracy: 92.83%\n",
      "Epoch 3, Batch 130/174, Loss: 0.2718, Training Accuracy: 92.74%\n",
      "Epoch 3, Batch 140/174, Loss: 0.2315, Training Accuracy: 92.77%\n",
      "Epoch 3, Batch 150/174, Loss: 0.2218, Training Accuracy: 92.79%\n",
      "Epoch 3, Batch 160/174, Loss: 0.2542, Training Accuracy: 92.78%\n",
      "Epoch 3, Batch 170/174, Loss: 0.2603, Training Accuracy: 92.69%\n",
      "Epoch 3, Training Accuracy: 92.68%, Validation Accuracy: 97.34%\n",
      "Epoch 4, Batch 10/174, Loss: 0.1053, Training Accuracy: 97.19%\n",
      "Epoch 4, Batch 20/174, Loss: 0.1101, Training Accuracy: 97.03%\n",
      "Epoch 4, Batch 30/174, Loss: 0.1277, Training Accuracy: 97.03%\n",
      "Epoch 4, Batch 40/174, Loss: 0.1050, Training Accuracy: 97.03%\n",
      "Epoch 4, Batch 50/174, Loss: 0.0936, Training Accuracy: 97.06%\n",
      "Epoch 4, Batch 60/174, Loss: 0.0845, Training Accuracy: 97.27%\n",
      "Epoch 4, Batch 70/174, Loss: 0.0673, Training Accuracy: 97.39%\n",
      "Epoch 4, Batch 80/174, Loss: 0.0836, Training Accuracy: 97.50%\n",
      "Epoch 4, Batch 90/174, Loss: 0.0850, Training Accuracy: 97.53%\n",
      "Epoch 4, Batch 100/174, Loss: 0.0798, Training Accuracy: 97.56%\n",
      "Epoch 4, Batch 110/174, Loss: 0.0937, Training Accuracy: 97.60%\n",
      "Epoch 4, Batch 120/174, Loss: 0.0817, Training Accuracy: 97.63%\n",
      "Epoch 4, Batch 130/174, Loss: 0.0920, Training Accuracy: 97.62%\n",
      "Epoch 4, Batch 140/174, Loss: 0.0767, Training Accuracy: 97.70%\n",
      "Epoch 4, Batch 150/174, Loss: 0.0689, Training Accuracy: 97.72%\n",
      "Epoch 4, Batch 160/174, Loss: 0.1038, Training Accuracy: 97.68%\n",
      "Epoch 4, Batch 170/174, Loss: 0.1011, Training Accuracy: 97.62%\n",
      "Epoch 4, Training Accuracy: 97.63%, Validation Accuracy: 99.28%\n",
      "Epoch 5, Batch 10/174, Loss: 0.0471, Training Accuracy: 99.06%\n",
      "Epoch 5, Batch 20/174, Loss: 0.0243, Training Accuracy: 99.53%\n",
      "Epoch 5, Batch 30/174, Loss: 0.0337, Training Accuracy: 99.48%\n",
      "Epoch 5, Batch 40/174, Loss: 0.0332, Training Accuracy: 99.53%\n",
      "Epoch 5, Batch 50/174, Loss: 0.0281, Training Accuracy: 99.53%\n",
      "Epoch 5, Batch 60/174, Loss: 0.0189, Training Accuracy: 99.58%\n",
      "Epoch 5, Batch 70/174, Loss: 0.0262, Training Accuracy: 99.58%\n",
      "Epoch 5, Batch 80/174, Loss: 0.0224, Training Accuracy: 99.57%\n",
      "Epoch 5, Batch 90/174, Loss: 0.0148, Training Accuracy: 99.62%\n",
      "Epoch 5, Batch 100/174, Loss: 0.0360, Training Accuracy: 99.55%\n",
      "Epoch 5, Batch 110/174, Loss: 0.0368, Training Accuracy: 99.52%\n",
      "Epoch 5, Batch 120/174, Loss: 0.0219, Training Accuracy: 99.54%\n",
      "Epoch 5, Batch 130/174, Loss: 0.0336, Training Accuracy: 99.54%\n",
      "Epoch 5, Batch 140/174, Loss: 0.0184, Training Accuracy: 99.55%\n",
      "Epoch 5, Batch 150/174, Loss: 0.0200, Training Accuracy: 99.57%\n",
      "Epoch 5, Batch 160/174, Loss: 0.0200, Training Accuracy: 99.59%\n",
      "Epoch 5, Batch 170/174, Loss: 0.0283, Training Accuracy: 99.59%\n",
      "Epoch 5, Training Accuracy: 99.59%, Validation Accuracy: 99.86%\n",
      "Epoch 6, Batch 10/174, Loss: 0.0076, Training Accuracy: 100.00%\n",
      "Epoch 6, Batch 20/174, Loss: 0.0152, Training Accuracy: 99.92%\n",
      "Epoch 6, Batch 30/174, Loss: 0.0139, Training Accuracy: 99.90%\n",
      "Epoch 6, Batch 40/174, Loss: 0.0258, Training Accuracy: 99.80%\n",
      "Epoch 6, Batch 50/174, Loss: 0.0239, Training Accuracy: 99.72%\n",
      "Epoch 6, Batch 60/174, Loss: 0.0098, Training Accuracy: 99.77%\n",
      "Epoch 6, Batch 70/174, Loss: 0.0173, Training Accuracy: 99.75%\n",
      "Epoch 6, Batch 80/174, Loss: 0.0191, Training Accuracy: 99.75%\n",
      "Epoch 6, Batch 90/174, Loss: 0.0077, Training Accuracy: 99.77%\n",
      "Epoch 6, Batch 100/174, Loss: 0.0074, Training Accuracy: 99.78%\n",
      "Epoch 6, Batch 110/174, Loss: 0.0131, Training Accuracy: 99.79%\n",
      "Epoch 6, Batch 120/174, Loss: 0.0085, Training Accuracy: 99.80%\n",
      "Epoch 6, Batch 130/174, Loss: 0.0119, Training Accuracy: 99.81%\n",
      "Epoch 6, Batch 140/174, Loss: 0.0069, Training Accuracy: 99.82%\n",
      "Epoch 6, Batch 150/174, Loss: 0.0214, Training Accuracy: 99.80%\n",
      "Epoch 6, Batch 160/174, Loss: 0.0109, Training Accuracy: 99.80%\n",
      "Epoch 6, Batch 170/174, Loss: 0.0164, Training Accuracy: 99.80%\n",
      "Epoch 6, Training Accuracy: 99.80%, Validation Accuracy: 99.86%\n",
      "Epoch 7, Batch 10/174, Loss: 0.0059, Training Accuracy: 100.00%\n",
      "Epoch 7, Batch 20/174, Loss: 0.0059, Training Accuracy: 100.00%\n",
      "Epoch 7, Batch 30/174, Loss: 0.0061, Training Accuracy: 100.00%\n",
      "Epoch 7, Batch 40/174, Loss: 0.0116, Training Accuracy: 99.96%\n",
      "Epoch 7, Batch 50/174, Loss: 0.0049, Training Accuracy: 99.97%\n",
      "Epoch 7, Batch 60/174, Loss: 0.0043, Training Accuracy: 99.97%\n",
      "Epoch 7, Batch 70/174, Loss: 0.0118, Training Accuracy: 99.96%\n",
      "Epoch 7, Batch 80/174, Loss: 0.0053, Training Accuracy: 99.96%\n",
      "Epoch 7, Batch 90/174, Loss: 0.0067, Training Accuracy: 99.97%\n",
      "Epoch 7, Batch 100/174, Loss: 0.0047, Training Accuracy: 99.97%\n",
      "Epoch 7, Batch 110/174, Loss: 0.0053, Training Accuracy: 99.97%\n",
      "Epoch 7, Batch 120/174, Loss: 0.0059, Training Accuracy: 99.96%\n",
      "Epoch 7, Batch 130/174, Loss: 0.0052, Training Accuracy: 99.96%\n",
      "Epoch 7, Batch 140/174, Loss: 0.0099, Training Accuracy: 99.96%\n",
      "Epoch 7, Batch 150/174, Loss: 0.0057, Training Accuracy: 99.96%\n",
      "Epoch 7, Batch 160/174, Loss: 0.0049, Training Accuracy: 99.96%\n",
      "Epoch 7, Batch 170/174, Loss: 0.0046, Training Accuracy: 99.96%\n",
      "Epoch 7, Training Accuracy: 99.96%, Validation Accuracy: 99.91%\n",
      "Epoch 8, Batch 10/174, Loss: 0.0038, Training Accuracy: 100.00%\n",
      "Epoch 8, Batch 20/174, Loss: 0.0043, Training Accuracy: 100.00%\n",
      "Epoch 8, Batch 30/174, Loss: 0.0101, Training Accuracy: 99.95%\n",
      "Epoch 8, Batch 40/174, Loss: 0.0041, Training Accuracy: 99.96%\n",
      "Epoch 8, Batch 50/174, Loss: 0.0041, Training Accuracy: 99.97%\n",
      "Epoch 8, Batch 60/174, Loss: 0.0036, Training Accuracy: 99.97%\n",
      "Epoch 8, Batch 70/174, Loss: 0.0069, Training Accuracy: 99.96%\n",
      "Epoch 8, Batch 80/174, Loss: 0.0037, Training Accuracy: 99.96%\n",
      "Epoch 8, Batch 90/174, Loss: 0.0046, Training Accuracy: 99.97%\n",
      "Epoch 8, Batch 100/174, Loss: 0.0041, Training Accuracy: 99.97%\n",
      "Epoch 8, Batch 110/174, Loss: 0.0046, Training Accuracy: 99.97%\n",
      "Epoch 8, Batch 120/174, Loss: 0.0042, Training Accuracy: 99.97%\n",
      "Epoch 8, Batch 130/174, Loss: 0.0039, Training Accuracy: 99.98%\n",
      "Epoch 8, Batch 140/174, Loss: 0.0036, Training Accuracy: 99.98%\n",
      "Epoch 8, Batch 150/174, Loss: 0.0040, Training Accuracy: 99.98%\n",
      "Epoch 8, Batch 160/174, Loss: 0.0036, Training Accuracy: 99.98%\n",
      "Epoch 8, Batch 170/174, Loss: 0.0033, Training Accuracy: 99.98%\n",
      "Epoch 8, Training Accuracy: 99.98%, Validation Accuracy: 99.95%\n",
      "Epoch 9, Batch 10/174, Loss: 0.0034, Training Accuracy: 100.00%\n",
      "Epoch 9, Batch 20/174, Loss: 0.0034, Training Accuracy: 100.00%\n",
      "Epoch 9, Batch 30/174, Loss: 0.0035, Training Accuracy: 100.00%\n",
      "Epoch 9, Batch 40/174, Loss: 0.0036, Training Accuracy: 100.00%\n",
      "Epoch 9, Batch 50/174, Loss: 0.0032, Training Accuracy: 100.00%\n",
      "Epoch 9, Batch 60/174, Loss: 0.0032, Training Accuracy: 100.00%\n",
      "Epoch 9, Batch 70/174, Loss: 0.0031, Training Accuracy: 100.00%\n",
      "Epoch 9, Batch 80/174, Loss: 0.0033, Training Accuracy: 100.00%\n",
      "Epoch 9, Batch 90/174, Loss: 0.0034, Training Accuracy: 100.00%\n",
      "Epoch 9, Batch 100/174, Loss: 0.0035, Training Accuracy: 100.00%\n",
      "Epoch 9, Batch 110/174, Loss: 0.0080, Training Accuracy: 99.99%\n",
      "Epoch 9, Batch 120/174, Loss: 0.0034, Training Accuracy: 99.99%\n",
      "Epoch 9, Batch 130/174, Loss: 0.0031, Training Accuracy: 99.99%\n",
      "Epoch 9, Batch 140/174, Loss: 0.0032, Training Accuracy: 99.99%\n",
      "Epoch 9, Batch 150/174, Loss: 0.0054, Training Accuracy: 99.98%\n",
      "Epoch 9, Batch 160/174, Loss: 0.0035, Training Accuracy: 99.98%\n",
      "Epoch 9, Batch 170/174, Loss: 0.0036, Training Accuracy: 99.98%\n",
      "Epoch 9, Training Accuracy: 99.98%, Validation Accuracy: 99.95%\n",
      "Epoch 10, Batch 10/174, Loss: 0.0034, Training Accuracy: 100.00%\n",
      "Epoch 10, Batch 20/174, Loss: 0.0027, Training Accuracy: 100.00%\n",
      "Epoch 10, Batch 30/174, Loss: 0.0031, Training Accuracy: 100.00%\n",
      "Epoch 10, Batch 40/174, Loss: 0.0033, Training Accuracy: 100.00%\n",
      "Epoch 10, Batch 50/174, Loss: 0.0031, Training Accuracy: 100.00%\n",
      "Epoch 10, Batch 60/174, Loss: 0.0032, Training Accuracy: 100.00%\n",
      "Epoch 10, Batch 70/174, Loss: 0.0029, Training Accuracy: 100.00%\n",
      "Epoch 10, Batch 80/174, Loss: 0.0032, Training Accuracy: 100.00%\n",
      "Epoch 10, Batch 90/174, Loss: 0.0031, Training Accuracy: 100.00%\n",
      "Epoch 10, Batch 100/174, Loss: 0.0028, Training Accuracy: 100.00%\n",
      "Epoch 10, Batch 110/174, Loss: 0.0070, Training Accuracy: 99.99%\n",
      "Epoch 10, Batch 120/174, Loss: 0.0031, Training Accuracy: 99.99%\n",
      "Epoch 10, Batch 130/174, Loss: 0.0030, Training Accuracy: 99.99%\n",
      "Epoch 10, Batch 140/174, Loss: 0.0029, Training Accuracy: 99.99%\n",
      "Epoch 10, Batch 150/174, Loss: 0.0032, Training Accuracy: 99.99%\n",
      "Epoch 10, Batch 160/174, Loss: 0.0028, Training Accuracy: 99.99%\n",
      "Epoch 10, Batch 170/174, Loss: 0.0043, Training Accuracy: 99.99%\n",
      "Epoch 10, Training Accuracy: 99.99%, Validation Accuracy: 99.95%\n",
      "Epoch 11, Batch 10/174, Loss: 0.0028, Training Accuracy: 100.00%\n",
      "Epoch 11, Batch 20/174, Loss: 0.0030, Training Accuracy: 100.00%\n",
      "Epoch 11, Batch 30/174, Loss: 0.0030, Training Accuracy: 100.00%\n",
      "Epoch 11, Batch 40/174, Loss: 0.0029, Training Accuracy: 100.00%\n",
      "Epoch 11, Batch 50/174, Loss: 0.0029, Training Accuracy: 100.00%\n",
      "Epoch 11, Batch 60/174, Loss: 0.0031, Training Accuracy: 100.00%\n",
      "Epoch 11, Batch 70/174, Loss: 0.0027, Training Accuracy: 100.00%\n",
      "Epoch 11, Batch 80/174, Loss: 0.0059, Training Accuracy: 99.98%\n",
      "Epoch 11, Batch 90/174, Loss: 0.0028, Training Accuracy: 99.98%\n",
      "Epoch 11, Batch 100/174, Loss: 0.0038, Training Accuracy: 99.98%\n",
      "Epoch 11, Batch 110/174, Loss: 0.0029, Training Accuracy: 99.99%\n",
      "Epoch 11, Batch 120/174, Loss: 0.0029, Training Accuracy: 99.99%\n",
      "Epoch 11, Batch 130/174, Loss: 0.0027, Training Accuracy: 99.99%\n",
      "Epoch 11, Batch 140/174, Loss: 0.0027, Training Accuracy: 99.99%\n",
      "Epoch 11, Batch 150/174, Loss: 0.0028, Training Accuracy: 99.99%\n",
      "Epoch 11, Batch 160/174, Loss: 0.0029, Training Accuracy: 99.99%\n",
      "Epoch 11, Batch 170/174, Loss: 0.0032, Training Accuracy: 99.99%\n",
      "Epoch 11, Training Accuracy: 99.99%, Validation Accuracy: 99.95%\n",
      "Epoch 12, Batch 10/174, Loss: 0.0029, Training Accuracy: 100.00%\n",
      "Epoch 12, Batch 20/174, Loss: 0.0028, Training Accuracy: 100.00%\n",
      "Epoch 12, Batch 30/174, Loss: 0.0053, Training Accuracy: 99.95%\n",
      "Epoch 12, Batch 40/174, Loss: 0.0031, Training Accuracy: 99.96%\n",
      "Epoch 12, Batch 50/174, Loss: 0.0027, Training Accuracy: 99.97%\n",
      "Epoch 12, Batch 60/174, Loss: 0.0029, Training Accuracy: 99.97%\n",
      "Epoch 12, Batch 70/174, Loss: 0.0027, Training Accuracy: 99.98%\n",
      "Epoch 12, Batch 80/174, Loss: 0.0026, Training Accuracy: 99.98%\n",
      "Epoch 12, Batch 90/174, Loss: 0.0029, Training Accuracy: 99.98%\n",
      "Epoch 12, Batch 100/174, Loss: 0.0028, Training Accuracy: 99.98%\n",
      "Epoch 12, Batch 110/174, Loss: 0.0026, Training Accuracy: 99.99%\n",
      "Epoch 12, Batch 120/174, Loss: 0.0025, Training Accuracy: 99.99%\n",
      "Epoch 12, Batch 130/174, Loss: 0.0027, Training Accuracy: 99.99%\n",
      "Epoch 12, Batch 140/174, Loss: 0.0030, Training Accuracy: 99.99%\n",
      "Epoch 12, Batch 150/174, Loss: 0.0029, Training Accuracy: 99.99%\n",
      "Epoch 12, Batch 160/174, Loss: 0.0027, Training Accuracy: 99.99%\n",
      "Epoch 12, Batch 170/174, Loss: 0.0030, Training Accuracy: 99.99%\n",
      "Epoch 12, Training Accuracy: 99.99%, Validation Accuracy: 99.95%\n",
      "Epoch 13, Batch 10/174, Loss: 0.0026, Training Accuracy: 100.00%\n",
      "Epoch 13, Batch 20/174, Loss: 0.0029, Training Accuracy: 100.00%\n",
      "Epoch 13, Batch 30/174, Loss: 0.0026, Training Accuracy: 100.00%\n",
      "Epoch 13, Batch 40/174, Loss: 0.0027, Training Accuracy: 100.00%\n",
      "Epoch 13, Batch 50/174, Loss: 0.0027, Training Accuracy: 100.00%\n",
      "Epoch 13, Batch 60/174, Loss: 0.0027, Training Accuracy: 100.00%\n",
      "Epoch 13, Batch 70/174, Loss: 0.0025, Training Accuracy: 100.00%\n",
      "Epoch 13, Batch 80/174, Loss: 0.0027, Training Accuracy: 100.00%\n",
      "Epoch 13, Batch 90/174, Loss: 0.0026, Training Accuracy: 100.00%\n",
      "Epoch 13, Batch 100/174, Loss: 0.0048, Training Accuracy: 99.98%\n",
      "Epoch 13, Batch 110/174, Loss: 0.0028, Training Accuracy: 99.99%\n",
      "Epoch 13, Batch 120/174, Loss: 0.0034, Training Accuracy: 99.99%\n",
      "Epoch 13, Batch 130/174, Loss: 0.0027, Training Accuracy: 99.99%\n",
      "Epoch 13, Batch 140/174, Loss: 0.0024, Training Accuracy: 99.99%\n",
      "Epoch 13, Batch 150/174, Loss: 0.0026, Training Accuracy: 99.99%\n",
      "Epoch 13, Batch 160/174, Loss: 0.0027, Training Accuracy: 99.99%\n",
      "Epoch 13, Batch 170/174, Loss: 0.0026, Training Accuracy: 99.99%\n",
      "Epoch 13, Training Accuracy: 99.99%, Validation Accuracy: 99.95%\n",
      "Epoch 14, Batch 10/174, Loss: 0.0028, Training Accuracy: 100.00%\n",
      "Epoch 14, Batch 20/174, Loss: 0.0025, Training Accuracy: 100.00%\n",
      "Epoch 14, Batch 30/174, Loss: 0.0025, Training Accuracy: 100.00%\n",
      "Epoch 14, Batch 40/174, Loss: 0.0025, Training Accuracy: 100.00%\n",
      "Epoch 14, Batch 50/174, Loss: 0.0028, Training Accuracy: 100.00%\n",
      "Epoch 14, Batch 60/174, Loss: 0.0025, Training Accuracy: 100.00%\n",
      "Epoch 14, Batch 70/174, Loss: 0.0027, Training Accuracy: 100.00%\n",
      "Epoch 14, Batch 80/174, Loss: 0.0046, Training Accuracy: 99.98%\n",
      "Epoch 14, Batch 90/174, Loss: 0.0026, Training Accuracy: 99.98%\n",
      "Epoch 14, Batch 100/174, Loss: 0.0026, Training Accuracy: 99.98%\n",
      "Epoch 14, Batch 110/174, Loss: 0.0028, Training Accuracy: 99.99%\n",
      "Epoch 14, Batch 120/174, Loss: 0.0026, Training Accuracy: 99.99%\n",
      "Epoch 14, Batch 130/174, Loss: 0.0025, Training Accuracy: 99.99%\n",
      "Epoch 14, Batch 140/174, Loss: 0.0023, Training Accuracy: 99.99%\n",
      "Epoch 14, Batch 150/174, Loss: 0.0026, Training Accuracy: 99.99%\n",
      "Epoch 14, Batch 160/174, Loss: 0.0024, Training Accuracy: 99.99%\n",
      "Epoch 14, Batch 170/174, Loss: 0.0033, Training Accuracy: 99.99%\n",
      "Epoch 14, Training Accuracy: 99.99%, Validation Accuracy: 99.95%\n",
      "Epoch 15, Batch 10/174, Loss: 0.0027, Training Accuracy: 100.00%\n",
      "Epoch 15, Batch 20/174, Loss: 0.0027, Training Accuracy: 100.00%\n",
      "Epoch 15, Batch 30/174, Loss: 0.0025, Training Accuracy: 100.00%\n",
      "Epoch 15, Batch 40/174, Loss: 0.0027, Training Accuracy: 100.00%\n",
      "Epoch 15, Batch 50/174, Loss: 0.0028, Training Accuracy: 100.00%\n",
      "Epoch 15, Batch 60/174, Loss: 0.0027, Training Accuracy: 100.00%\n",
      "Epoch 15, Batch 70/174, Loss: 0.0024, Training Accuracy: 100.00%\n",
      "Epoch 15, Batch 80/174, Loss: 0.0040, Training Accuracy: 99.98%\n",
      "Epoch 15, Batch 90/174, Loss: 0.0027, Training Accuracy: 99.98%\n",
      "Epoch 15, Batch 100/174, Loss: 0.0025, Training Accuracy: 99.98%\n",
      "Epoch 15, Batch 110/174, Loss: 0.0031, Training Accuracy: 99.99%\n",
      "Epoch 15, Batch 120/174, Loss: 0.0024, Training Accuracy: 99.99%\n",
      "Epoch 15, Batch 130/174, Loss: 0.0024, Training Accuracy: 99.99%\n",
      "Epoch 15, Batch 140/174, Loss: 0.0023, Training Accuracy: 99.99%\n",
      "Epoch 15, Batch 150/174, Loss: 0.0024, Training Accuracy: 99.99%\n",
      "Epoch 15, Batch 160/174, Loss: 0.0026, Training Accuracy: 99.99%\n",
      "Epoch 15, Batch 170/174, Loss: 0.0024, Training Accuracy: 99.99%\n",
      "Epoch 15, Training Accuracy: 99.99%, Validation Accuracy: 99.95%\n",
      "Epoch 16, Batch 10/174, Loss: 0.0030, Training Accuracy: 100.00%\n",
      "Epoch 16, Batch 20/174, Loss: 0.0026, Training Accuracy: 100.00%\n",
      "Epoch 16, Batch 30/174, Loss: 0.0025, Training Accuracy: 100.00%\n",
      "Epoch 16, Batch 40/174, Loss: 0.0026, Training Accuracy: 100.00%\n",
      "Epoch 16, Batch 50/174, Loss: 0.0023, Training Accuracy: 100.00%\n",
      "Epoch 16, Batch 60/174, Loss: 0.0025, Training Accuracy: 100.00%\n",
      "Epoch 16, Batch 70/174, Loss: 0.0022, Training Accuracy: 100.00%\n",
      "Epoch 16, Batch 80/174, Loss: 0.0026, Training Accuracy: 100.00%\n",
      "Epoch 16, Batch 90/174, Loss: 0.0026, Training Accuracy: 100.00%\n",
      "Epoch 16, Batch 100/174, Loss: 0.0023, Training Accuracy: 100.00%\n",
      "Epoch 16, Batch 110/174, Loss: 0.0026, Training Accuracy: 100.00%\n",
      "Epoch 16, Batch 120/174, Loss: 0.0024, Training Accuracy: 100.00%\n",
      "Epoch 16, Batch 130/174, Loss: 0.0043, Training Accuracy: 99.99%\n",
      "Epoch 16, Batch 140/174, Loss: 0.0025, Training Accuracy: 99.99%\n",
      "Epoch 16, Batch 150/174, Loss: 0.0025, Training Accuracy: 99.99%\n",
      "Epoch 16, Batch 160/174, Loss: 0.0024, Training Accuracy: 99.99%\n",
      "Epoch 16, Batch 170/174, Loss: 0.0026, Training Accuracy: 99.99%\n",
      "Epoch 16, Training Accuracy: 99.99%, Validation Accuracy: 99.95%\n",
      "Epoch 17, Batch 10/174, Loss: 0.0025, Training Accuracy: 100.00%\n",
      "Epoch 17, Batch 20/174, Loss: 0.0025, Training Accuracy: 100.00%\n",
      "Epoch 17, Batch 30/174, Loss: 0.0026, Training Accuracy: 100.00%\n",
      "Epoch 17, Batch 40/174, Loss: 0.0027, Training Accuracy: 100.00%\n",
      "Epoch 17, Batch 50/174, Loss: 0.0025, Training Accuracy: 100.00%\n",
      "Epoch 17, Batch 60/174, Loss: 0.0024, Training Accuracy: 100.00%\n",
      "Epoch 17, Batch 70/174, Loss: 0.0044, Training Accuracy: 99.98%\n",
      "Epoch 17, Batch 80/174, Loss: 0.0028, Training Accuracy: 99.98%\n",
      "Epoch 17, Batch 90/174, Loss: 0.0027, Training Accuracy: 99.98%\n",
      "Epoch 17, Batch 100/174, Loss: 0.0024, Training Accuracy: 99.98%\n",
      "Epoch 17, Batch 110/174, Loss: 0.0027, Training Accuracy: 99.99%\n",
      "Epoch 17, Batch 120/174, Loss: 0.0025, Training Accuracy: 99.99%\n",
      "Epoch 17, Batch 130/174, Loss: 0.0021, Training Accuracy: 99.99%\n",
      "Epoch 17, Batch 140/174, Loss: 0.0023, Training Accuracy: 99.99%\n",
      "Epoch 17, Batch 150/174, Loss: 0.0024, Training Accuracy: 99.99%\n",
      "Epoch 17, Batch 160/174, Loss: 0.0024, Training Accuracy: 99.99%\n",
      "Epoch 17, Batch 170/174, Loss: 0.0024, Training Accuracy: 99.99%\n",
      "Epoch 17, Training Accuracy: 99.99%, Validation Accuracy: 100.00%\n",
      "Epoch 18, Batch 10/174, Loss: 0.0027, Training Accuracy: 100.00%\n",
      "Epoch 18, Batch 20/174, Loss: 0.0026, Training Accuracy: 100.00%\n",
      "Epoch 18, Batch 30/174, Loss: 0.0042, Training Accuracy: 100.00%\n",
      "Epoch 18, Batch 40/174, Loss: 0.0028, Training Accuracy: 100.00%\n",
      "Epoch 18, Batch 50/174, Loss: 0.0023, Training Accuracy: 100.00%\n",
      "Epoch 18, Batch 60/174, Loss: 0.0024, Training Accuracy: 100.00%\n",
      "Epoch 18, Batch 70/174, Loss: 0.0025, Training Accuracy: 100.00%\n",
      "Epoch 18, Batch 80/174, Loss: 0.0025, Training Accuracy: 100.00%\n",
      "Epoch 18, Batch 90/174, Loss: 0.0023, Training Accuracy: 100.00%\n",
      "Epoch 18, Batch 100/174, Loss: 0.0023, Training Accuracy: 100.00%\n",
      "Epoch 18, Batch 110/174, Loss: 0.0025, Training Accuracy: 100.00%\n",
      "Epoch 18, Batch 120/174, Loss: 0.0023, Training Accuracy: 100.00%\n",
      "Epoch 18, Batch 130/174, Loss: 0.0024, Training Accuracy: 100.00%\n",
      "Epoch 18, Batch 140/174, Loss: 0.0024, Training Accuracy: 100.00%\n",
      "Epoch 18, Batch 150/174, Loss: 0.0028, Training Accuracy: 100.00%\n",
      "Epoch 18, Batch 160/174, Loss: 0.0021, Training Accuracy: 100.00%\n",
      "Epoch 18, Batch 170/174, Loss: 0.0026, Training Accuracy: 100.00%\n",
      "Epoch 18, Training Accuracy: 100.00%, Validation Accuracy: 100.00%\n",
      "Epoch 19, Batch 10/174, Loss: 0.0030, Training Accuracy: 100.00%\n",
      "Epoch 19, Batch 20/174, Loss: 0.0024, Training Accuracy: 100.00%\n",
      "Epoch 19, Batch 30/174, Loss: 0.0023, Training Accuracy: 100.00%\n",
      "Epoch 19, Batch 40/174, Loss: 0.0040, Training Accuracy: 100.00%\n",
      "Epoch 19, Batch 50/174, Loss: 0.0022, Training Accuracy: 100.00%\n",
      "Epoch 19, Batch 60/174, Loss: 0.0022, Training Accuracy: 100.00%\n",
      "Epoch 19, Batch 70/174, Loss: 0.0024, Training Accuracy: 100.00%\n",
      "Epoch 19, Batch 80/174, Loss: 0.0028, Training Accuracy: 100.00%\n",
      "Epoch 19, Batch 90/174, Loss: 0.0027, Training Accuracy: 100.00%\n",
      "Epoch 19, Batch 100/174, Loss: 0.0025, Training Accuracy: 100.00%\n",
      "Epoch 19, Batch 110/174, Loss: 0.0025, Training Accuracy: 100.00%\n",
      "Epoch 19, Batch 120/174, Loss: 0.0023, Training Accuracy: 100.00%\n",
      "Epoch 19, Batch 130/174, Loss: 0.0024, Training Accuracy: 100.00%\n",
      "Epoch 19, Batch 140/174, Loss: 0.0024, Training Accuracy: 100.00%\n",
      "Epoch 19, Batch 150/174, Loss: 0.0025, Training Accuracy: 100.00%\n",
      "Epoch 19, Batch 160/174, Loss: 0.0024, Training Accuracy: 100.00%\n",
      "Epoch 19, Batch 170/174, Loss: 0.0024, Training Accuracy: 100.00%\n",
      "Epoch 19, Training Accuracy: 100.00%, Validation Accuracy: 100.00%\n",
      "Epoch 20, Batch 10/174, Loss: 0.0025, Training Accuracy: 100.00%\n",
      "Epoch 20, Batch 20/174, Loss: 0.0023, Training Accuracy: 100.00%\n",
      "Epoch 20, Batch 30/174, Loss: 0.0025, Training Accuracy: 100.00%\n",
      "Epoch 20, Batch 40/174, Loss: 0.0024, Training Accuracy: 100.00%\n",
      "Epoch 20, Batch 50/174, Loss: 0.0039, Training Accuracy: 100.00%\n",
      "Epoch 20, Batch 60/174, Loss: 0.0025, Training Accuracy: 100.00%\n",
      "Epoch 20, Batch 70/174, Loss: 0.0024, Training Accuracy: 100.00%\n",
      "Epoch 20, Batch 80/174, Loss: 0.0022, Training Accuracy: 100.00%\n",
      "Epoch 20, Batch 90/174, Loss: 0.0025, Training Accuracy: 100.00%\n",
      "Epoch 20, Batch 100/174, Loss: 0.0022, Training Accuracy: 100.00%\n",
      "Epoch 20, Batch 110/174, Loss: 0.0023, Training Accuracy: 100.00%\n",
      "Epoch 20, Batch 120/174, Loss: 0.0024, Training Accuracy: 100.00%\n",
      "Epoch 20, Batch 130/174, Loss: 0.0024, Training Accuracy: 100.00%\n",
      "Epoch 20, Batch 140/174, Loss: 0.0022, Training Accuracy: 100.00%\n",
      "Epoch 20, Batch 150/174, Loss: 0.0027, Training Accuracy: 100.00%\n",
      "Epoch 20, Batch 160/174, Loss: 0.0033, Training Accuracy: 100.00%\n",
      "Epoch 20, Batch 170/174, Loss: 0.0024, Training Accuracy: 100.00%\n",
      "Epoch 20, Training Accuracy: 100.00%, Validation Accuracy: 100.00%\n",
      "Test Accuracy: 89.09%\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        if batch_idx % 10 == 9:  # Print every 10 batches\n",
    "            print(f\"Epoch {epoch+1}, Batch {batch_idx+1}/{len(train_loader)}, Loss: {running_loss / 10:.4f}, Training Accuracy: {100 * correct / total:.2f}%\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # Validation accuracy calculation\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for val_inputs, val_labels in val_loader:\n",
    "            val_outputs = model(val_inputs)\n",
    "            _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "            val_total += val_labels.size(0)\n",
    "            val_correct += (val_predicted == val_labels).sum().item()\n",
    "\n",
    "    val_accuracy = 100 * val_correct / val_total\n",
    "    print(f\"Epoch {epoch+1}, Training Accuracy: {100 * correct / total:.2f}%, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "# Evaluation on the test set\n",
    "model.eval()\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test_inputs, test_labels in test_loader:\n",
    "        test_outputs = model(test_inputs)\n",
    "        _, test_predicted = torch.max(test_outputs.data, 1)\n",
    "        test_total += test_labels.size(0)\n",
    "        test_correct += (test_predicted == test_labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * test_correct / test_total:.2f}%\")\n",
    "torch.save(model.state_dict(), 'ViT_11_pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViT(\n",
       "  (to_patch_embedding): Sequential(\n",
       "    (0): Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=32, p2=32)\n",
       "    (1): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): Linear(in_features=3072, out_features=128, bias=True)\n",
       "    (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer): Linformer(\n",
       "    (net): SequentialSequence(\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x ModuleList(\n",
       "          (0): PreNorm(\n",
       "            (fn): LinformerSelfAttention(\n",
       "              (to_q): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (to_k): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (to_v): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (to_out): Linear(in_features=128, out_features=128, bias=True)\n",
       "            )\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): PreNorm(\n",
       "            (fn): FeedForward(\n",
       "              (w1): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (w2): Linear(in_features=512, out_features=128, bias=True)\n",
       "            )\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (to_latent): Identity()\n",
       "  (mlp_head): Sequential(\n",
       "    (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): Linear(in_features=128, out_features=11, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the models\n",
    "model = ViT(\n",
    "    dim=128,\n",
    "    image_size=224,\n",
    "    patch_size=32,\n",
    "    num_classes=11,\n",
    "    transformer=efficient_transformer,\n",
    "    channels=3,\n",
    ")\n",
    "model.load_state_dict(torch.load(\"C:\\\\Users\\\\Admin\\\\AppData\\\\Local\\\\Programs\\\\Microsoft VS Code\\\\ViT_11_pth\"))  # Load the trained model weights\n",
    "model.eval()  # Set the model to evaluation mode\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
