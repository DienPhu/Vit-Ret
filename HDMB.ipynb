{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import glob\n",
    "from itertools import chain\n",
    "import os\n",
    "import random\n",
    "import cv2  # Assuming you have OpenCV installed\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import cv2\n",
    "from linformer import Linformer\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.notebook import tqdm\n",
    "import itertools\n",
    "import math\n",
    "from vit_pytorch.efficient import ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Parameters\n",
    "dataset = \"C:\\\\Study\\\\OJT\\\\Dataset\\\\HDMB\"         # Dataset path\n",
    "dataset2 = \"C:\\\\Study\\\\OJT\\\\Dataset_Extraction\\\\HDMB\\\\Full\"               # Dataset2 path\n",
    "train_path = \"C:\\\\Study\\\\OJT\\\\Dataset_Extraction\\\\HDMB\\\\HDMBTrain\"            # Training path\n",
    "test_path = \"C:\\\\Study\\\\OJT\\\\Dataset_Extraction\\\\HDMB\\\\HDMBTest\"            # Testing path\n",
    "no_of_frames = 10000                     # Total number of frames to be extracted\n",
    "categories = os.listdir(dataset)        # Name of each class/category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A folder C:\\Study\\OJT\\Dataset_Extraction\\HDMB\\Full already exists...\n"
     ]
    }
   ],
   "source": [
    "# Creating dataset directory\n",
    "try:\n",
    "    os.mkdir(dataset2)\n",
    "    print(\"Folder {} created...\".format(dataset2))\n",
    "except:\n",
    "    print(\"A folder {} already exists...\".format(dataset2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A folder C:\\Study\\OJT\\Dataset_Extraction\\HDMB\\HDMBTrain already exists...\n"
     ]
    }
   ],
   "source": [
    "# Creating training_set directory\n",
    "try:\n",
    "    os.mkdir(train_path)\n",
    "    print(\"Folder {} created...\".format(train_path))\n",
    "except:\n",
    "    print(\"A folder {} already exists...\".format(train_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A folder C:\\Study\\OJT\\Dataset_Extraction\\HDMB\\HDMBTest already exists...\n"
     ]
    }
   ],
   "source": [
    "# Creating testing_set directory\n",
    "try:\n",
    "    os.mkdir(test_path)\n",
    "    print(\"Folder {} created...\".format(test_path))\n",
    "except:\n",
    "    print(\"A folder {} already exists...\".format(test_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder brush_hair created...\n",
      "Folder cartwheel created...\n",
      "Folder catch created...\n",
      "Folder chew created...\n",
      "Folder clap created...\n",
      "Folder climb created...\n",
      "Folder climb_stairs created...\n",
      "Folder dive created...\n",
      "Folder draw_sword created...\n",
      "Folder dribble created...\n",
      "Folder drink created...\n",
      "Folder eat created...\n",
      "Folder fall_floor created...\n",
      "Folder fencing created...\n",
      "Folder flic_flac created...\n",
      "Folder golf created...\n",
      "Folder handstand created...\n",
      "Folder hit created...\n",
      "Folder hug created...\n",
      "Folder jump created...\n",
      "Folder kick created...\n",
      "Folder kick_ball created...\n",
      "Folder kiss created...\n",
      "Folder laugh created...\n",
      "Folder pick created...\n",
      "Folder pour created...\n",
      "Folder pullup created...\n",
      "Folder punch created...\n",
      "Folder push created...\n",
      "Folder pushup created...\n",
      "Folder ride_bike created...\n",
      "Folder ride_horse created...\n",
      "Folder run created...\n",
      "Folder shake_hands created...\n",
      "Folder shoot_ball created...\n",
      "Folder shoot_bow created...\n",
      "Folder shoot_gun created...\n",
      "Folder sit created...\n",
      "Folder situp created...\n",
      "Folder smile created...\n",
      "Folder smoke created...\n",
      "Folder somersault created...\n",
      "Folder stand created...\n",
      "Folder swing_baseball created...\n",
      "Folder sword created...\n",
      "Folder sword_exercise created...\n",
      "Folder talk created...\n",
      "Folder throw created...\n",
      "Folder turn created...\n",
      "Folder walk created...\n",
      "Folder wave created...\n"
     ]
    }
   ],
   "source": [
    "# Creating same directories for dataset2/ that are already present in the dataset directory\n",
    "for category in categories:\n",
    "    try:\n",
    "        os.mkdir(os.path.join(dataset2, category))\n",
    "        print(\"Folder {} created...\".format(category))\n",
    "    except:\n",
    "        print(\"A folder already exists, named {}...\".format(category, dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder brush_hair created...\n",
      "Folder cartwheel created...\n",
      "Folder catch created...\n",
      "Folder chew created...\n",
      "Folder clap created...\n",
      "Folder climb created...\n",
      "Folder climb_stairs created...\n",
      "Folder dive created...\n",
      "Folder draw_sword created...\n",
      "Folder dribble created...\n",
      "Folder drink created...\n",
      "Folder eat created...\n",
      "Folder fall_floor created...\n",
      "Folder fencing created...\n",
      "Folder flic_flac created...\n",
      "Folder golf created...\n",
      "Folder handstand created...\n",
      "Folder hit created...\n",
      "Folder hug created...\n",
      "Folder jump created...\n",
      "Folder kick created...\n",
      "Folder kick_ball created...\n",
      "Folder kiss created...\n",
      "Folder laugh created...\n",
      "Folder pick created...\n",
      "Folder pour created...\n",
      "Folder pullup created...\n",
      "Folder punch created...\n",
      "Folder push created...\n",
      "Folder pushup created...\n",
      "Folder ride_bike created...\n",
      "Folder ride_horse created...\n",
      "Folder run created...\n",
      "Folder shake_hands created...\n",
      "Folder shoot_ball created...\n",
      "Folder shoot_bow created...\n",
      "Folder shoot_gun created...\n",
      "Folder sit created...\n",
      "Folder situp created...\n",
      "Folder smile created...\n",
      "Folder smoke created...\n",
      "Folder somersault created...\n",
      "Folder stand created...\n",
      "Folder swing_baseball created...\n",
      "Folder sword created...\n",
      "Folder sword_exercise created...\n",
      "Folder talk created...\n",
      "Folder throw created...\n",
      "Folder turn created...\n",
      "Folder walk created...\n",
      "Folder wave created...\n"
     ]
    }
   ],
   "source": [
    "for category in categories:\n",
    "    try:\n",
    "        os.mkdir(os.path.join(train_path, category))\n",
    "        print(\"Folder {} created...\".format(category))\n",
    "    except:\n",
    "        print(\"A folder already exists, named {}...\".format(category, train_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder brush_hair created...\n",
      "Folder cartwheel created...\n",
      "Folder catch created...\n",
      "Folder chew created...\n",
      "Folder clap created...\n",
      "Folder climb created...\n",
      "Folder climb_stairs created...\n",
      "Folder dive created...\n",
      "Folder draw_sword created...\n",
      "Folder dribble created...\n",
      "Folder drink created...\n",
      "Folder eat created...\n",
      "Folder fall_floor created...\n",
      "Folder fencing created...\n",
      "Folder flic_flac created...\n",
      "Folder golf created...\n",
      "Folder handstand created...\n",
      "Folder hit created...\n",
      "Folder hug created...\n",
      "Folder jump created...\n",
      "Folder kick created...\n",
      "Folder kick_ball created...\n",
      "Folder kiss created...\n",
      "Folder laugh created...\n",
      "Folder pick created...\n",
      "Folder pour created...\n",
      "Folder pullup created...\n",
      "Folder punch created...\n",
      "Folder push created...\n",
      "Folder pushup created...\n",
      "Folder ride_bike created...\n",
      "Folder ride_horse created...\n",
      "Folder run created...\n",
      "Folder shake_hands created...\n",
      "Folder shoot_ball created...\n",
      "Folder shoot_bow created...\n",
      "Folder shoot_gun created...\n",
      "Folder sit created...\n",
      "Folder situp created...\n",
      "Folder smile created...\n",
      "Folder smoke created...\n",
      "Folder somersault created...\n",
      "Folder stand created...\n",
      "Folder swing_baseball created...\n",
      "Folder sword created...\n",
      "Folder sword_exercise created...\n",
      "Folder talk created...\n",
      "Folder throw created...\n",
      "Folder turn created...\n",
      "Folder walk created...\n",
      "Folder wave created...\n"
     ]
    }
   ],
   "source": [
    "# Creating same directories for testing_set/ that are already present in the dataset directory\n",
    "for category in categories:\n",
    "    try:\n",
    "        os.mkdir(os.path.join(test_path, category))\n",
    "        print(\"Folder {} created...\".format(category))\n",
    "    except:\n",
    "        print(\"A folder already exists, named {}...\".format(category, test_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bad292d2b976490e84c610f13b227bc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Combining multiple videos into single video file\n",
    "for category in tqdm(categories):\n",
    "    videofiles = glob.glob(os.path.join(dataset, category, \"**/*.avi\"), recursive=True)\n",
    "    if videofiles:\n",
    "        cap = cv2.VideoCapture(videofiles[0])\n",
    "    else:\n",
    "        print(\"No video files found in {}/{}\".format(dataset, category))\n",
    "    video_index = 0\n",
    "    cap = cv2.VideoCapture(videofiles[0])    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "    # fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "    out = cv2.VideoWriter(\"{}/{}/{}.avi\".format(dataset2, category, category), fourcc, 25, (320, 240))\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if frame is None:\n",
    "            video_index += 1\n",
    "            if video_index >= len(videofiles):\n",
    "                break\n",
    "            else:\n",
    "                cap = cv2.VideoCapture(videofiles[ video_index ])\n",
    "                ret, frame = cap.read()\n",
    "                out.write(frame)\n",
    "        else:\n",
    "            out.write(frame)\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a14bbaae9d6b454f8fa70ea970d90eba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23568, 6323, 2496, 8390, 7386, 15656, 4505, 6458, 6144, 6521, 1593, 942, 440, 5092, 6473, 6820, 8112, 3042, 5188, 1356, 1571, 4060, 11018, 20026, 4706, 16864, 6888, 3609, 8165, 8087, 7433, 12346, 4307, 5974, 8254, 19333, 7753, 1771, 7235, 5736, 9619, 7374, 2944, 10541, 4943, 7535, 346, 7727, 2856, 11534, 3984]\n"
     ]
    }
   ],
   "source": [
    "# Saving total no. of frames of each classes/categories into an array\n",
    "total_frames = []\n",
    "for category in tqdm(categories):\n",
    "    cap = cv2.VideoCapture(dataset2 + \"/\" + category + \"/\" + category + \".avi\")\n",
    "    length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    total_frames.append(length)\n",
    "    cap.release()\n",
    "    \n",
    "print(total_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42cdda74c88d4b538c3bf2dbeb682b2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extracting one frame per five frame from the Videos\n",
    "for category in tqdm(categories):\n",
    "    count = 0    \n",
    "    a = glob.glob(dataset2 + '/' + category + '/' + category +'.avi')\n",
    "    for i in range(len(a)):\n",
    "        cap = cv2.VideoCapture(a[i])\n",
    "        frameRate = cap.get(5)\n",
    "        while(cap.isOpened()):\n",
    "            frameId = cap.get(1)\n",
    "            ret, frame = cap.read()\n",
    "            if (ret != True):\n",
    "                break\n",
    "            if (frameId % math.floor(frameRate) == 0):\n",
    "                cv2.imwrite(train_path + '/' + category + '/{}_{}.jpg'.format(category, count), frame)\n",
    "                count += 1\n",
    "        cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8f7439d7743402aad0f433c1c5163ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Moving 150 random images from training_set into testing_set\n",
    "for category in tqdm(categories):\n",
    "    sub_file = [file for file in glob.glob(train_path +'/'+ category +'/'+ \"*.jpg\")]\n",
    "    test_files = random.sample(sub_file, 10)\n",
    "    for test_file in test_files:\n",
    "        img = cv2.imread(test_file)\n",
    "        os.remove(test_file)\n",
    "        test_filename = os.path.basename(test_file)\n",
    "        cv2.imwrite(test_path +'/' + category + '/' + test_filename , img)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "lr = 0.001\n",
    "gamma = 0.7\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformation for loading and preprocessing images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),  # You can adjust the crop size as needed\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom dataset for the entire training set\n",
    "full_dataset = ImageFolder(train_path, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and validation sets\n",
    "train_size = int(0.8 * len(full_dataset))  # 80% for training\n",
    "val_size = len(full_dataset) - train_size  # 20% for validation\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom datasets for training and test\n",
    "train_dataset = ImageFolder(train_path, transform=transform)\n",
    "test_dataset = ImageFolder(test_path, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders for training and test sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficient_transformer = Linformer(\n",
    "    dim=128,\n",
    "    seq_len=49+1,  # 7x7 patches + 1 cls-token\n",
    "    depth=12,\n",
    "    heads=8,\n",
    "    k=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ViT(\n",
    "    dim=128,\n",
    "    image_size=224,\n",
    "    patch_size=32,\n",
    "    num_classes=51,\n",
    "    transformer=efficient_transformer,\n",
    "    channels=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "# scheduler\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 10/210, Loss: 3.8115, Training Accuracy: 8.28%\n",
      "Epoch 1, Batch 20/210, Loss: 3.7255, Training Accuracy: 7.81%\n",
      "Epoch 1, Batch 30/210, Loss: 3.6287, Training Accuracy: 8.18%\n",
      "Epoch 1, Batch 40/210, Loss: 3.5153, Training Accuracy: 8.98%\n",
      "Epoch 1, Batch 50/210, Loss: 3.4471, Training Accuracy: 9.88%\n",
      "Epoch 1, Batch 60/210, Loss: 3.2512, Training Accuracy: 11.02%\n",
      "Epoch 1, Batch 70/210, Loss: 3.2306, Training Accuracy: 12.12%\n",
      "Epoch 1, Batch 80/210, Loss: 3.0312, Training Accuracy: 13.38%\n",
      "Epoch 1, Batch 90/210, Loss: 3.0305, Training Accuracy: 14.46%\n",
      "Epoch 1, Batch 100/210, Loss: 2.8927, Training Accuracy: 15.73%\n",
      "Epoch 1, Batch 110/210, Loss: 2.8245, Training Accuracy: 16.72%\n",
      "Epoch 1, Batch 120/210, Loss: 2.7538, Training Accuracy: 17.90%\n",
      "Epoch 1, Batch 130/210, Loss: 2.7681, Training Accuracy: 18.85%\n",
      "Epoch 1, Batch 140/210, Loss: 2.6130, Training Accuracy: 20.15%\n",
      "Epoch 1, Batch 150/210, Loss: 2.5598, Training Accuracy: 21.26%\n",
      "Epoch 1, Batch 160/210, Loss: 2.4632, Training Accuracy: 22.38%\n",
      "Epoch 1, Batch 170/210, Loss: 2.3846, Training Accuracy: 23.45%\n",
      "Epoch 1, Batch 180/210, Loss: 2.4021, Training Accuracy: 24.41%\n",
      "Epoch 1, Batch 190/210, Loss: 2.2983, Training Accuracy: 25.39%\n",
      "Epoch 1, Batch 200/210, Loss: 2.2781, Training Accuracy: 26.35%\n",
      "Epoch 1, Batch 210/210, Loss: 2.1793, Training Accuracy: 27.25%\n",
      "Epoch 1, Training Accuracy: 27.25%, Validation Accuracy: 50.35%\n",
      "Epoch 2, Batch 10/210, Loss: 1.9777, Training Accuracy: 49.38%\n",
      "Epoch 2, Batch 20/210, Loss: 1.8493, Training Accuracy: 52.50%\n",
      "Epoch 2, Batch 30/210, Loss: 1.8193, Training Accuracy: 53.23%\n",
      "Epoch 2, Batch 40/210, Loss: 1.7659, Training Accuracy: 53.95%\n",
      "Epoch 2, Batch 50/210, Loss: 1.6286, Training Accuracy: 54.84%\n",
      "Epoch 2, Batch 60/210, Loss: 1.7280, Training Accuracy: 55.36%\n",
      "Epoch 2, Batch 70/210, Loss: 1.6879, Training Accuracy: 55.87%\n",
      "Epoch 2, Batch 80/210, Loss: 1.6593, Training Accuracy: 56.05%\n",
      "Epoch 2, Batch 90/210, Loss: 1.6639, Training Accuracy: 56.41%\n",
      "Epoch 2, Batch 100/210, Loss: 1.5713, Training Accuracy: 56.92%\n",
      "Epoch 2, Batch 110/210, Loss: 1.5020, Training Accuracy: 57.30%\n",
      "Epoch 2, Batch 120/210, Loss: 1.6998, Training Accuracy: 57.08%\n",
      "Epoch 2, Batch 130/210, Loss: 1.4797, Training Accuracy: 57.48%\n",
      "Epoch 2, Batch 140/210, Loss: 1.6332, Training Accuracy: 57.50%\n",
      "Epoch 2, Batch 150/210, Loss: 1.4982, Training Accuracy: 57.74%\n",
      "Epoch 2, Batch 160/210, Loss: 1.4285, Training Accuracy: 58.16%\n",
      "Epoch 2, Batch 170/210, Loss: 1.4981, Training Accuracy: 58.32%\n",
      "Epoch 2, Batch 180/210, Loss: 1.3913, Training Accuracy: 58.65%\n",
      "Epoch 2, Batch 190/210, Loss: 1.4495, Training Accuracy: 58.88%\n",
      "Epoch 2, Batch 200/210, Loss: 1.3820, Training Accuracy: 59.22%\n",
      "Epoch 2, Batch 210/210, Loss: 1.3098, Training Accuracy: 59.47%\n",
      "Epoch 2, Training Accuracy: 59.47%, Validation Accuracy: 74.49%\n",
      "Epoch 3, Batch 10/210, Loss: 1.0154, Training Accuracy: 72.97%\n",
      "Epoch 3, Batch 20/210, Loss: 1.0449, Training Accuracy: 73.36%\n",
      "Epoch 3, Batch 30/210, Loss: 0.9340, Training Accuracy: 74.22%\n",
      "Epoch 3, Batch 40/210, Loss: 0.9609, Training Accuracy: 74.34%\n",
      "Epoch 3, Batch 50/210, Loss: 0.9043, Training Accuracy: 75.16%\n",
      "Epoch 3, Batch 60/210, Loss: 0.8901, Training Accuracy: 75.60%\n",
      "Epoch 3, Batch 70/210, Loss: 0.9178, Training Accuracy: 75.69%\n",
      "Epoch 3, Batch 80/210, Loss: 0.8997, Training Accuracy: 75.72%\n",
      "Epoch 3, Batch 90/210, Loss: 0.8945, Training Accuracy: 75.71%\n",
      "Epoch 3, Batch 100/210, Loss: 0.9536, Training Accuracy: 75.75%\n",
      "Epoch 3, Batch 110/210, Loss: 0.8438, Training Accuracy: 75.82%\n",
      "Epoch 3, Batch 120/210, Loss: 0.8400, Training Accuracy: 76.13%\n",
      "Epoch 3, Batch 130/210, Loss: 0.8597, Training Accuracy: 76.20%\n",
      "Epoch 3, Batch 140/210, Loss: 0.8449, Training Accuracy: 76.34%\n",
      "Epoch 3, Batch 150/210, Loss: 0.8288, Training Accuracy: 76.49%\n",
      "Epoch 3, Batch 160/210, Loss: 0.7983, Training Accuracy: 76.59%\n",
      "Epoch 3, Batch 170/210, Loss: 0.8242, Training Accuracy: 76.73%\n",
      "Epoch 3, Batch 180/210, Loss: 0.9237, Training Accuracy: 76.64%\n",
      "Epoch 3, Batch 190/210, Loss: 0.8646, Training Accuracy: 76.62%\n",
      "Epoch 3, Batch 200/210, Loss: 0.8725, Training Accuracy: 76.65%\n",
      "Epoch 3, Batch 210/210, Loss: 0.8199, Training Accuracy: 76.84%\n",
      "Epoch 3, Training Accuracy: 76.84%, Validation Accuracy: 87.36%\n",
      "Epoch 4, Batch 10/210, Loss: 0.5632, Training Accuracy: 85.00%\n",
      "Epoch 4, Batch 20/210, Loss: 0.4949, Training Accuracy: 85.94%\n",
      "Epoch 4, Batch 30/210, Loss: 0.4790, Training Accuracy: 87.03%\n",
      "Epoch 4, Batch 40/210, Loss: 0.4368, Training Accuracy: 87.89%\n",
      "Epoch 4, Batch 50/210, Loss: 0.4992, Training Accuracy: 87.81%\n",
      "Epoch 4, Batch 60/210, Loss: 0.4594, Training Accuracy: 88.05%\n",
      "Epoch 4, Batch 70/210, Loss: 0.4704, Training Accuracy: 88.10%\n",
      "Epoch 4, Batch 80/210, Loss: 0.4004, Training Accuracy: 88.42%\n",
      "Epoch 4, Batch 90/210, Loss: 0.4659, Training Accuracy: 88.39%\n",
      "Epoch 4, Batch 100/210, Loss: 0.4530, Training Accuracy: 88.48%\n",
      "Epoch 4, Batch 110/210, Loss: 0.3956, Training Accuracy: 88.62%\n",
      "Epoch 4, Batch 120/210, Loss: 0.4696, Training Accuracy: 88.55%\n",
      "Epoch 4, Batch 130/210, Loss: 0.4829, Training Accuracy: 88.52%\n",
      "Epoch 4, Batch 140/210, Loss: 0.4091, Training Accuracy: 88.56%\n",
      "Epoch 4, Batch 150/210, Loss: 0.3825, Training Accuracy: 88.69%\n",
      "Epoch 4, Batch 160/210, Loss: 0.4497, Training Accuracy: 88.65%\n",
      "Epoch 4, Batch 170/210, Loss: 0.3816, Training Accuracy: 88.73%\n",
      "Epoch 4, Batch 180/210, Loss: 0.4878, Training Accuracy: 88.67%\n",
      "Epoch 4, Batch 190/210, Loss: 0.4441, Training Accuracy: 88.67%\n",
      "Epoch 4, Batch 200/210, Loss: 0.4579, Training Accuracy: 88.68%\n",
      "Epoch 4, Batch 210/210, Loss: 0.4241, Training Accuracy: 88.67%\n",
      "Epoch 4, Training Accuracy: 88.67%, Validation Accuracy: 94.82%\n",
      "Epoch 5, Batch 10/210, Loss: 0.2496, Training Accuracy: 94.06%\n",
      "Epoch 5, Batch 20/210, Loss: 0.2594, Training Accuracy: 94.45%\n",
      "Epoch 5, Batch 30/210, Loss: 0.1855, Training Accuracy: 95.21%\n",
      "Epoch 5, Batch 40/210, Loss: 0.2185, Training Accuracy: 95.16%\n",
      "Epoch 5, Batch 50/210, Loss: 0.2320, Training Accuracy: 95.25%\n",
      "Epoch 5, Batch 60/210, Loss: 0.1893, Training Accuracy: 95.21%\n",
      "Epoch 5, Batch 70/210, Loss: 0.1989, Training Accuracy: 95.42%\n",
      "Epoch 5, Batch 80/210, Loss: 0.2057, Training Accuracy: 95.41%\n",
      "Epoch 5, Batch 90/210, Loss: 0.2060, Training Accuracy: 95.50%\n",
      "Epoch 5, Batch 100/210, Loss: 0.1747, Training Accuracy: 95.61%\n",
      "Epoch 5, Batch 110/210, Loss: 0.1859, Training Accuracy: 95.65%\n",
      "Epoch 5, Batch 120/210, Loss: 0.1902, Training Accuracy: 95.79%\n",
      "Epoch 5, Batch 130/210, Loss: 0.2428, Training Accuracy: 95.65%\n",
      "Epoch 5, Batch 140/210, Loss: 0.1849, Training Accuracy: 95.70%\n",
      "Epoch 5, Batch 150/210, Loss: 0.1811, Training Accuracy: 95.70%\n",
      "Epoch 5, Batch 160/210, Loss: 0.1717, Training Accuracy: 95.74%\n",
      "Epoch 5, Batch 170/210, Loss: 0.2012, Training Accuracy: 95.68%\n",
      "Epoch 5, Batch 180/210, Loss: 0.2265, Training Accuracy: 95.61%\n",
      "Epoch 5, Batch 190/210, Loss: 0.1781, Training Accuracy: 95.67%\n",
      "Epoch 5, Batch 200/210, Loss: 0.1901, Training Accuracy: 95.66%\n",
      "Epoch 5, Batch 210/210, Loss: 0.2383, Training Accuracy: 95.62%\n",
      "Epoch 5, Training Accuracy: 95.62%, Validation Accuracy: 98.69%\n",
      "Epoch 6, Batch 10/210, Loss: 0.1040, Training Accuracy: 98.75%\n",
      "Epoch 6, Batch 20/210, Loss: 0.1196, Training Accuracy: 98.44%\n",
      "Epoch 6, Batch 30/210, Loss: 0.1050, Training Accuracy: 98.49%\n",
      "Epoch 6, Batch 40/210, Loss: 0.0883, Training Accuracy: 98.48%\n",
      "Epoch 6, Batch 50/210, Loss: 0.0963, Training Accuracy: 98.59%\n",
      "Epoch 6, Batch 60/210, Loss: 0.0954, Training Accuracy: 98.65%\n",
      "Epoch 6, Batch 70/210, Loss: 0.0946, Training Accuracy: 98.57%\n",
      "Epoch 6, Batch 80/210, Loss: 0.0849, Training Accuracy: 98.61%\n",
      "Epoch 6, Batch 90/210, Loss: 0.0909, Training Accuracy: 98.61%\n",
      "Epoch 6, Batch 100/210, Loss: 0.0865, Training Accuracy: 98.64%\n",
      "Epoch 6, Batch 110/210, Loss: 0.0899, Training Accuracy: 98.61%\n",
      "Epoch 6, Batch 120/210, Loss: 0.0949, Training Accuracy: 98.59%\n",
      "Epoch 6, Batch 130/210, Loss: 0.0845, Training Accuracy: 98.59%\n",
      "Epoch 6, Batch 140/210, Loss: 0.0716, Training Accuracy: 98.60%\n",
      "Epoch 6, Batch 150/210, Loss: 0.0833, Training Accuracy: 98.64%\n",
      "Epoch 6, Batch 160/210, Loss: 0.0921, Training Accuracy: 98.59%\n",
      "Epoch 6, Batch 170/210, Loss: 0.0890, Training Accuracy: 98.62%\n",
      "Epoch 6, Batch 180/210, Loss: 0.0877, Training Accuracy: 98.65%\n",
      "Epoch 6, Batch 190/210, Loss: 0.0749, Training Accuracy: 98.65%\n",
      "Epoch 6, Batch 200/210, Loss: 0.0834, Training Accuracy: 98.63%\n",
      "Epoch 6, Batch 210/210, Loss: 0.1029, Training Accuracy: 98.61%\n",
      "Epoch 6, Training Accuracy: 98.61%, Validation Accuracy: 99.59%\n",
      "Epoch 7, Batch 10/210, Loss: 0.0589, Training Accuracy: 99.38%\n",
      "Epoch 7, Batch 20/210, Loss: 0.0528, Training Accuracy: 99.45%\n",
      "Epoch 7, Batch 30/210, Loss: 0.0449, Training Accuracy: 99.58%\n",
      "Epoch 7, Batch 40/210, Loss: 0.0480, Training Accuracy: 99.49%\n",
      "Epoch 7, Batch 50/210, Loss: 0.0516, Training Accuracy: 99.50%\n",
      "Epoch 7, Batch 60/210, Loss: 0.0417, Training Accuracy: 99.56%\n",
      "Epoch 7, Batch 70/210, Loss: 0.0517, Training Accuracy: 99.53%\n",
      "Epoch 7, Batch 80/210, Loss: 0.0518, Training Accuracy: 99.47%\n",
      "Epoch 7, Batch 90/210, Loss: 0.0439, Training Accuracy: 99.51%\n",
      "Epoch 7, Batch 100/210, Loss: 0.0482, Training Accuracy: 99.52%\n",
      "Epoch 7, Batch 110/210, Loss: 0.0542, Training Accuracy: 99.49%\n",
      "Epoch 7, Batch 120/210, Loss: 0.0474, Training Accuracy: 99.48%\n",
      "Epoch 7, Batch 130/210, Loss: 0.0455, Training Accuracy: 99.50%\n",
      "Epoch 7, Batch 140/210, Loss: 0.0613, Training Accuracy: 99.45%\n",
      "Epoch 7, Batch 150/210, Loss: 0.0475, Training Accuracy: 99.45%\n",
      "Epoch 7, Batch 160/210, Loss: 0.0414, Training Accuracy: 99.46%\n",
      "Epoch 7, Batch 170/210, Loss: 0.0492, Training Accuracy: 99.45%\n",
      "Epoch 7, Batch 180/210, Loss: 0.0383, Training Accuracy: 99.47%\n",
      "Epoch 7, Batch 190/210, Loss: 0.0514, Training Accuracy: 99.47%\n",
      "Epoch 7, Batch 200/210, Loss: 0.0410, Training Accuracy: 99.49%\n",
      "Epoch 7, Batch 210/210, Loss: 0.0434, Training Accuracy: 99.49%\n",
      "Epoch 7, Training Accuracy: 99.49%, Validation Accuracy: 99.70%\n",
      "Epoch 8, Batch 10/210, Loss: 0.0353, Training Accuracy: 99.84%\n",
      "Epoch 8, Batch 20/210, Loss: 0.0317, Training Accuracy: 99.84%\n",
      "Epoch 8, Batch 30/210, Loss: 0.0279, Training Accuracy: 99.90%\n",
      "Epoch 8, Batch 40/210, Loss: 0.0347, Training Accuracy: 99.84%\n",
      "Epoch 8, Batch 50/210, Loss: 0.0306, Training Accuracy: 99.81%\n",
      "Epoch 8, Batch 60/210, Loss: 0.0281, Training Accuracy: 99.82%\n",
      "Epoch 8, Batch 70/210, Loss: 0.0313, Training Accuracy: 99.82%\n",
      "Epoch 8, Batch 80/210, Loss: 0.0266, Training Accuracy: 99.82%\n",
      "Epoch 8, Batch 90/210, Loss: 0.0291, Training Accuracy: 99.81%\n",
      "Epoch 8, Batch 100/210, Loss: 0.0321, Training Accuracy: 99.83%\n",
      "Epoch 8, Batch 110/210, Loss: 0.0369, Training Accuracy: 99.79%\n",
      "Epoch 8, Batch 120/210, Loss: 0.0370, Training Accuracy: 99.79%\n",
      "Epoch 8, Batch 130/210, Loss: 0.0399, Training Accuracy: 99.76%\n",
      "Epoch 8, Batch 140/210, Loss: 0.0263, Training Accuracy: 99.77%\n",
      "Epoch 8, Batch 150/210, Loss: 0.0282, Training Accuracy: 99.77%\n",
      "Epoch 8, Batch 160/210, Loss: 0.0323, Training Accuracy: 99.77%\n",
      "Epoch 8, Batch 170/210, Loss: 0.0319, Training Accuracy: 99.77%\n",
      "Epoch 8, Batch 180/210, Loss: 0.0328, Training Accuracy: 99.76%\n",
      "Epoch 8, Batch 190/210, Loss: 0.0330, Training Accuracy: 99.75%\n",
      "Epoch 8, Batch 200/210, Loss: 0.0278, Training Accuracy: 99.75%\n",
      "Epoch 8, Batch 210/210, Loss: 0.0303, Training Accuracy: 99.75%\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        if batch_idx % 10 == 9:  # Print every 10 batches\n",
    "            print(f\"Epoch {epoch+1}, Batch {batch_idx+1}/{len(train_loader)}, Loss: {running_loss / 10:.4f}, Training Accuracy: {100 * correct / total:.2f}%\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # Validation accuracy calculation\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for val_inputs, val_labels in val_loader:\n",
    "            val_outputs = model(val_inputs)\n",
    "            _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "            val_total += val_labels.size(0)\n",
    "            val_correct += (val_predicted == val_labels).sum().item()\n",
    "\n",
    "    val_accuracy = 100 * val_correct / val_total\n",
    "    print(f\"Epoch {epoch+1}, Training Accuracy: {100 * correct / total:.2f}%, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "# Evaluation on the test set\n",
    "model.eval()\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test_inputs, test_labels in test_loader:\n",
    "        test_outputs = model(test_inputs)\n",
    "        _, test_predicted = torch.max(test_outputs.data, 1)\n",
    "        test_total += test_labels.size(0)\n",
    "        test_correct += (test_predicted == test_labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * test_correct / test_total:.2f}%\")\n",
    "torch.save(model.state_dict(), 'ViT_HDMB_pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
