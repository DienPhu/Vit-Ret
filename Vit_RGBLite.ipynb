{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Essential Libraries\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import glob\n",
    "from itertools import chain\n",
    "import os\n",
    "import random\n",
    "import cv2  # Assuming you have OpenCV installed\n",
    "from torchvision.datasets import ImageFolder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import cv2\n",
    "import torchvision\n",
    "from linformer import Linformer\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.notebook import tqdm\n",
    "import itertools\n",
    "\n",
    "from vit_pytorch.efficient import ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"C:\\\\Study\\\\OJT\\\\Dataset_Extraction\\\\Vit2\\\\Train\"\n",
    "test_path =\"C:\\\\Study\\\\OJT\\\\Dataset_Extraction\\\\Vit2\\\\Test\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficient_transformer = Linformer(\n",
    "    dim=128,\n",
    "    seq_len=49+1,  # 7x7 patches + 1 cls-token\n",
    "    depth=12,\n",
    "    heads=8,\n",
    "    k=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ViT(\n",
    "    dim=128,\n",
    "    image_size=224,\n",
    "    patch_size=32,\n",
    "    num_classes=27,\n",
    "    transformer=efficient_transformer,\n",
    "    channels=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "lr = 0.001\n",
    "gamma = 0.7\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer\n",
    "optimizer = optim.Adamax(model.parameters(), lr=lr)\n",
    "# scheduler\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformation for loading and preprocessing images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),  # You can adjust the crop size as needed\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom dataset for the entire training set\n",
    "full_dataset = ImageFolder(train_path, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and validation sets\n",
    "train_size = int(0.8 * len(full_dataset))  # 80% for training\n",
    "val_size = len(full_dataset) - train_size  # 20% for validation\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom datasets for training and test\n",
    "train_dataset = ImageFolder(train_path, transform=transform)\n",
    "test_dataset = ImageFolder(test_path, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders for training and test sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 10/103, Loss: 3.4608, Training Accuracy: 4.53%\n",
      "Epoch 1, Batch 20/103, Loss: 3.3385, Training Accuracy: 4.53%\n",
      "Epoch 1, Batch 30/103, Loss: 3.3147, Training Accuracy: 4.53%\n",
      "Epoch 1, Batch 40/103, Loss: 3.3044, Training Accuracy: 4.45%\n",
      "Epoch 1, Batch 50/103, Loss: 3.3105, Training Accuracy: 4.25%\n",
      "Epoch 1, Batch 60/103, Loss: 3.2835, Training Accuracy: 4.32%\n",
      "Epoch 1, Batch 70/103, Loss: 3.2826, Training Accuracy: 4.17%\n",
      "Epoch 1, Batch 80/103, Loss: 3.2042, Training Accuracy: 4.86%\n",
      "Epoch 1, Batch 90/103, Loss: 3.0763, Training Accuracy: 5.54%\n",
      "Epoch 1, Batch 100/103, Loss: 2.9570, Training Accuracy: 6.27%\n",
      "Epoch 1, Training Accuracy: 6.24%, Validation Accuracy: 11.47%\n",
      "Epoch 2, Batch 10/103, Loss: 2.8264, Training Accuracy: 13.12%\n",
      "Epoch 2, Batch 20/103, Loss: 2.8209, Training Accuracy: 14.06%\n",
      "Epoch 2, Batch 30/103, Loss: 2.8154, Training Accuracy: 14.11%\n",
      "Epoch 2, Batch 40/103, Loss: 2.7130, Training Accuracy: 14.22%\n",
      "Epoch 2, Batch 50/103, Loss: 2.6456, Training Accuracy: 14.69%\n",
      "Epoch 2, Batch 60/103, Loss: 2.6042, Training Accuracy: 15.08%\n",
      "Epoch 2, Batch 70/103, Loss: 2.5563, Training Accuracy: 15.65%\n",
      "Epoch 2, Batch 80/103, Loss: 2.5714, Training Accuracy: 16.07%\n",
      "Epoch 2, Batch 90/103, Loss: 2.4193, Training Accuracy: 16.79%\n",
      "Epoch 2, Batch 100/103, Loss: 2.3597, Training Accuracy: 17.47%\n",
      "Epoch 2, Training Accuracy: 17.61%, Validation Accuracy: 27.64%\n",
      "Epoch 3, Batch 10/103, Loss: 2.1603, Training Accuracy: 31.88%\n",
      "Epoch 3, Batch 20/103, Loss: 2.1314, Training Accuracy: 30.78%\n",
      "Epoch 3, Batch 30/103, Loss: 2.1570, Training Accuracy: 29.27%\n",
      "Epoch 3, Batch 40/103, Loss: 2.0998, Training Accuracy: 29.18%\n",
      "Epoch 3, Batch 50/103, Loss: 2.0061, Training Accuracy: 30.16%\n",
      "Epoch 3, Batch 60/103, Loss: 1.9661, Training Accuracy: 30.78%\n",
      "Epoch 3, Batch 70/103, Loss: 1.9578, Training Accuracy: 31.14%\n",
      "Epoch 3, Batch 80/103, Loss: 1.8986, Training Accuracy: 31.52%\n",
      "Epoch 3, Batch 90/103, Loss: 1.8645, Training Accuracy: 31.68%\n",
      "Epoch 3, Batch 100/103, Loss: 1.8011, Training Accuracy: 32.39%\n",
      "Epoch 3, Training Accuracy: 32.57%, Validation Accuracy: 38.72%\n",
      "Epoch 4, Batch 10/103, Loss: 1.6610, Training Accuracy: 43.12%\n",
      "Epoch 4, Batch 20/103, Loss: 1.6260, Training Accuracy: 42.73%\n",
      "Epoch 4, Batch 30/103, Loss: 1.6070, Training Accuracy: 43.85%\n",
      "Epoch 4, Batch 40/103, Loss: 1.5408, Training Accuracy: 44.53%\n",
      "Epoch 4, Batch 50/103, Loss: 1.5888, Training Accuracy: 44.50%\n",
      "Epoch 4, Batch 60/103, Loss: 1.5132, Training Accuracy: 45.26%\n",
      "Epoch 4, Batch 70/103, Loss: 1.5057, Training Accuracy: 45.54%\n",
      "Epoch 4, Batch 80/103, Loss: 1.4937, Training Accuracy: 45.59%\n",
      "Epoch 4, Batch 90/103, Loss: 1.4536, Training Accuracy: 45.94%\n",
      "Epoch 4, Batch 100/103, Loss: 1.4462, Training Accuracy: 46.03%\n",
      "Epoch 4, Training Accuracy: 46.19%, Validation Accuracy: 52.70%\n",
      "Epoch 5, Batch 10/103, Loss: 1.3056, Training Accuracy: 55.94%\n",
      "Epoch 5, Batch 20/103, Loss: 1.3693, Training Accuracy: 54.45%\n",
      "Epoch 5, Batch 30/103, Loss: 1.2793, Training Accuracy: 55.31%\n",
      "Epoch 5, Batch 40/103, Loss: 1.2423, Training Accuracy: 55.74%\n",
      "Epoch 5, Batch 50/103, Loss: 1.2271, Training Accuracy: 55.91%\n",
      "Epoch 5, Batch 60/103, Loss: 1.2434, Training Accuracy: 56.15%\n",
      "Epoch 5, Batch 70/103, Loss: 1.1956, Training Accuracy: 56.14%\n",
      "Epoch 5, Batch 80/103, Loss: 1.2345, Training Accuracy: 56.19%\n",
      "Epoch 5, Batch 90/103, Loss: 1.1935, Training Accuracy: 56.63%\n",
      "Epoch 5, Batch 100/103, Loss: 1.1415, Training Accuracy: 56.98%\n",
      "Epoch 5, Training Accuracy: 57.05%, Validation Accuracy: 59.76%\n",
      "Epoch 6, Batch 10/103, Loss: 1.1256, Training Accuracy: 59.22%\n",
      "Epoch 6, Batch 20/103, Loss: 1.0596, Training Accuracy: 61.41%\n",
      "Epoch 6, Batch 30/103, Loss: 1.0725, Training Accuracy: 62.03%\n",
      "Epoch 6, Batch 40/103, Loss: 1.0617, Training Accuracy: 62.77%\n",
      "Epoch 6, Batch 50/103, Loss: 1.0200, Training Accuracy: 63.19%\n",
      "Epoch 6, Batch 60/103, Loss: 0.9998, Training Accuracy: 63.26%\n",
      "Epoch 6, Batch 70/103, Loss: 1.0317, Training Accuracy: 63.66%\n",
      "Epoch 6, Batch 80/103, Loss: 1.0420, Training Accuracy: 63.73%\n",
      "Epoch 6, Batch 90/103, Loss: 1.0728, Training Accuracy: 63.61%\n",
      "Epoch 6, Batch 100/103, Loss: 1.0752, Training Accuracy: 63.42%\n",
      "Epoch 6, Training Accuracy: 63.66%, Validation Accuracy: 64.01%\n",
      "Epoch 7, Batch 10/103, Loss: 0.9750, Training Accuracy: 67.03%\n",
      "Epoch 7, Batch 20/103, Loss: 0.9671, Training Accuracy: 66.95%\n",
      "Epoch 7, Batch 30/103, Loss: 0.9021, Training Accuracy: 68.02%\n",
      "Epoch 7, Batch 40/103, Loss: 0.9186, Training Accuracy: 68.28%\n",
      "Epoch 7, Batch 50/103, Loss: 0.9439, Training Accuracy: 67.84%\n",
      "Epoch 7, Batch 60/103, Loss: 0.9527, Training Accuracy: 67.63%\n",
      "Epoch 7, Batch 70/103, Loss: 0.8812, Training Accuracy: 67.95%\n",
      "Epoch 7, Batch 80/103, Loss: 0.8809, Training Accuracy: 68.20%\n",
      "Epoch 7, Batch 90/103, Loss: 0.8468, Training Accuracy: 68.75%\n",
      "Epoch 7, Batch 100/103, Loss: 0.8402, Training Accuracy: 69.27%\n",
      "Epoch 7, Training Accuracy: 69.16%, Validation Accuracy: 71.91%\n",
      "Epoch 8, Batch 10/103, Loss: 0.8276, Training Accuracy: 72.66%\n",
      "Epoch 8, Batch 20/103, Loss: 0.8194, Training Accuracy: 72.97%\n",
      "Epoch 8, Batch 30/103, Loss: 0.8330, Training Accuracy: 73.28%\n",
      "Epoch 8, Batch 40/103, Loss: 0.8260, Training Accuracy: 73.44%\n",
      "Epoch 8, Batch 50/103, Loss: 0.7686, Training Accuracy: 73.88%\n",
      "Epoch 8, Batch 60/103, Loss: 0.8210, Training Accuracy: 73.39%\n",
      "Epoch 8, Batch 70/103, Loss: 0.7909, Training Accuracy: 73.42%\n",
      "Epoch 8, Batch 80/103, Loss: 0.7833, Training Accuracy: 73.40%\n",
      "Epoch 8, Batch 90/103, Loss: 0.8072, Training Accuracy: 73.35%\n",
      "Epoch 8, Batch 100/103, Loss: 0.8130, Training Accuracy: 73.12%\n",
      "Epoch 8, Training Accuracy: 73.05%, Validation Accuracy: 74.64%\n",
      "Epoch 9, Batch 10/103, Loss: 0.7660, Training Accuracy: 73.75%\n",
      "Epoch 9, Batch 20/103, Loss: 0.7718, Training Accuracy: 74.45%\n",
      "Epoch 9, Batch 30/103, Loss: 0.7695, Training Accuracy: 74.48%\n",
      "Epoch 9, Batch 40/103, Loss: 0.7087, Training Accuracy: 75.55%\n",
      "Epoch 9, Batch 50/103, Loss: 0.7587, Training Accuracy: 75.94%\n",
      "Epoch 9, Batch 60/103, Loss: 0.7492, Training Accuracy: 75.65%\n",
      "Epoch 9, Batch 70/103, Loss: 0.7236, Training Accuracy: 75.80%\n",
      "Epoch 9, Batch 80/103, Loss: 0.7487, Training Accuracy: 75.72%\n",
      "Epoch 9, Batch 90/103, Loss: 0.7260, Training Accuracy: 75.68%\n",
      "Epoch 9, Batch 100/103, Loss: 0.7075, Training Accuracy: 75.77%\n",
      "Epoch 9, Training Accuracy: 75.87%, Validation Accuracy: 77.90%\n",
      "Epoch 10, Batch 10/103, Loss: 0.7026, Training Accuracy: 77.19%\n",
      "Epoch 10, Batch 20/103, Loss: 0.7288, Training Accuracy: 77.11%\n",
      "Epoch 10, Batch 30/103, Loss: 0.6998, Training Accuracy: 77.34%\n",
      "Epoch 10, Batch 40/103, Loss: 0.7358, Training Accuracy: 77.23%\n",
      "Epoch 10, Batch 50/103, Loss: 0.6990, Training Accuracy: 77.25%\n",
      "Epoch 10, Batch 60/103, Loss: 0.7036, Training Accuracy: 77.14%\n",
      "Epoch 10, Batch 70/103, Loss: 0.6979, Training Accuracy: 76.99%\n",
      "Epoch 10, Batch 80/103, Loss: 0.6860, Training Accuracy: 77.07%\n",
      "Epoch 10, Batch 90/103, Loss: 0.6458, Training Accuracy: 77.38%\n",
      "Epoch 10, Batch 100/103, Loss: 0.6437, Training Accuracy: 77.77%\n",
      "Epoch 10, Training Accuracy: 77.83%, Validation Accuracy: 78.13%\n",
      "Epoch 11, Batch 10/103, Loss: 0.6515, Training Accuracy: 78.75%\n",
      "Epoch 11, Batch 20/103, Loss: 0.6542, Training Accuracy: 79.14%\n",
      "Epoch 11, Batch 30/103, Loss: 0.6384, Training Accuracy: 79.32%\n",
      "Epoch 11, Batch 40/103, Loss: 0.6371, Training Accuracy: 80.08%\n",
      "Epoch 11, Batch 50/103, Loss: 0.6881, Training Accuracy: 79.66%\n",
      "Epoch 11, Batch 60/103, Loss: 0.6966, Training Accuracy: 79.45%\n",
      "Epoch 11, Batch 70/103, Loss: 0.6584, Training Accuracy: 79.08%\n",
      "Epoch 11, Batch 80/103, Loss: 0.6619, Training Accuracy: 78.95%\n",
      "Epoch 11, Batch 90/103, Loss: 0.6499, Training Accuracy: 78.99%\n",
      "Epoch 11, Batch 100/103, Loss: 0.6530, Training Accuracy: 79.03%\n",
      "Epoch 11, Training Accuracy: 79.02%, Validation Accuracy: 80.18%\n",
      "Epoch 12, Batch 10/103, Loss: 0.6052, Training Accuracy: 82.34%\n",
      "Epoch 12, Batch 20/103, Loss: 0.6476, Training Accuracy: 80.23%\n",
      "Epoch 12, Batch 30/103, Loss: 0.6329, Training Accuracy: 80.21%\n",
      "Epoch 12, Batch 40/103, Loss: 0.6508, Training Accuracy: 80.39%\n",
      "Epoch 12, Batch 50/103, Loss: 0.6484, Training Accuracy: 80.19%\n",
      "Epoch 12, Batch 60/103, Loss: 0.6318, Training Accuracy: 80.03%\n",
      "Epoch 12, Batch 70/103, Loss: 0.6512, Training Accuracy: 79.93%\n",
      "Epoch 12, Batch 80/103, Loss: 0.6372, Training Accuracy: 79.82%\n",
      "Epoch 12, Batch 90/103, Loss: 0.6621, Training Accuracy: 79.67%\n",
      "Epoch 12, Batch 100/103, Loss: 0.6303, Training Accuracy: 79.72%\n",
      "Epoch 12, Training Accuracy: 79.78%, Validation Accuracy: 80.56%\n",
      "Epoch 13, Batch 10/103, Loss: 0.6314, Training Accuracy: 80.16%\n",
      "Epoch 13, Batch 20/103, Loss: 0.6316, Training Accuracy: 79.84%\n",
      "Epoch 13, Batch 30/103, Loss: 0.6174, Training Accuracy: 80.31%\n",
      "Epoch 13, Batch 40/103, Loss: 0.6246, Training Accuracy: 80.51%\n",
      "Epoch 13, Batch 50/103, Loss: 0.6141, Training Accuracy: 80.69%\n",
      "Epoch 13, Batch 60/103, Loss: 0.6076, Training Accuracy: 80.78%\n",
      "Epoch 13, Batch 70/103, Loss: 0.6523, Training Accuracy: 80.74%\n",
      "Epoch 13, Batch 80/103, Loss: 0.6168, Training Accuracy: 80.92%\n",
      "Epoch 13, Batch 90/103, Loss: 0.5952, Training Accuracy: 80.78%\n",
      "Epoch 13, Batch 100/103, Loss: 0.6100, Training Accuracy: 80.67%\n",
      "Epoch 13, Training Accuracy: 80.77%, Validation Accuracy: 80.56%\n",
      "Epoch 14, Batch 10/103, Loss: 0.6279, Training Accuracy: 80.62%\n",
      "Epoch 14, Batch 20/103, Loss: 0.6281, Training Accuracy: 80.16%\n",
      "Epoch 14, Batch 30/103, Loss: 0.6014, Training Accuracy: 80.36%\n",
      "Epoch 14, Batch 40/103, Loss: 0.5912, Training Accuracy: 80.86%\n",
      "Epoch 14, Batch 50/103, Loss: 0.6093, Training Accuracy: 81.25%\n",
      "Epoch 14, Batch 60/103, Loss: 0.5733, Training Accuracy: 81.51%\n",
      "Epoch 14, Batch 70/103, Loss: 0.5853, Training Accuracy: 81.29%\n",
      "Epoch 14, Batch 80/103, Loss: 0.6580, Training Accuracy: 80.86%\n",
      "Epoch 14, Batch 90/103, Loss: 0.6129, Training Accuracy: 80.87%\n",
      "Epoch 14, Batch 100/103, Loss: 0.6036, Training Accuracy: 81.02%\n",
      "Epoch 14, Training Accuracy: 81.22%, Validation Accuracy: 81.02%\n",
      "Epoch 15, Batch 10/103, Loss: 0.5817, Training Accuracy: 82.66%\n",
      "Epoch 15, Batch 20/103, Loss: 0.6287, Training Accuracy: 81.56%\n",
      "Epoch 15, Batch 30/103, Loss: 0.6097, Training Accuracy: 81.20%\n",
      "Epoch 15, Batch 40/103, Loss: 0.5965, Training Accuracy: 80.90%\n",
      "Epoch 15, Batch 50/103, Loss: 0.5997, Training Accuracy: 81.47%\n",
      "Epoch 15, Batch 60/103, Loss: 0.6071, Training Accuracy: 81.48%\n",
      "Epoch 15, Batch 70/103, Loss: 0.5946, Training Accuracy: 81.67%\n",
      "Epoch 15, Batch 80/103, Loss: 0.5771, Training Accuracy: 81.88%\n",
      "Epoch 15, Batch 90/103, Loss: 0.5903, Training Accuracy: 81.72%\n",
      "Epoch 15, Batch 100/103, Loss: 0.5784, Training Accuracy: 81.72%\n",
      "Epoch 15, Training Accuracy: 81.63%, Validation Accuracy: 82.31%\n",
      "Epoch 16, Batch 10/103, Loss: 0.6149, Training Accuracy: 80.62%\n",
      "Epoch 16, Batch 20/103, Loss: 0.5765, Training Accuracy: 82.03%\n",
      "Epoch 16, Batch 30/103, Loss: 0.5571, Training Accuracy: 83.02%\n",
      "Epoch 16, Batch 40/103, Loss: 0.6057, Training Accuracy: 82.62%\n",
      "Epoch 16, Batch 50/103, Loss: 0.5962, Training Accuracy: 82.75%\n",
      "Epoch 16, Batch 60/103, Loss: 0.5739, Training Accuracy: 82.97%\n",
      "Epoch 16, Batch 70/103, Loss: 0.5977, Training Accuracy: 82.57%\n",
      "Epoch 16, Batch 80/103, Loss: 0.6093, Training Accuracy: 82.50%\n",
      "Epoch 16, Batch 90/103, Loss: 0.6231, Training Accuracy: 82.10%\n",
      "Epoch 16, Batch 100/103, Loss: 0.5834, Training Accuracy: 82.17%\n",
      "Epoch 16, Training Accuracy: 82.19%, Validation Accuracy: 82.76%\n",
      "Epoch 17, Batch 10/103, Loss: 0.6371, Training Accuracy: 78.44%\n",
      "Epoch 17, Batch 20/103, Loss: 0.5870, Training Accuracy: 81.56%\n",
      "Epoch 17, Batch 30/103, Loss: 0.5679, Training Accuracy: 82.24%\n",
      "Epoch 17, Batch 40/103, Loss: 0.6027, Training Accuracy: 82.23%\n",
      "Epoch 17, Batch 50/103, Loss: 0.5757, Training Accuracy: 82.03%\n",
      "Epoch 17, Batch 60/103, Loss: 0.5644, Training Accuracy: 82.53%\n",
      "Epoch 17, Batch 70/103, Loss: 0.5969, Training Accuracy: 82.57%\n",
      "Epoch 17, Batch 80/103, Loss: 0.6198, Training Accuracy: 82.29%\n",
      "Epoch 17, Batch 90/103, Loss: 0.5740, Training Accuracy: 82.34%\n",
      "Epoch 17, Batch 100/103, Loss: 0.5942, Training Accuracy: 82.33%\n",
      "Epoch 17, Training Accuracy: 82.39%, Validation Accuracy: 82.92%\n",
      "Epoch 18, Batch 10/103, Loss: 0.5795, Training Accuracy: 83.59%\n",
      "Epoch 18, Batch 20/103, Loss: 0.5878, Training Accuracy: 83.91%\n",
      "Epoch 18, Batch 30/103, Loss: 0.5896, Training Accuracy: 83.12%\n",
      "Epoch 18, Batch 40/103, Loss: 0.5926, Training Accuracy: 82.70%\n",
      "Epoch 18, Batch 50/103, Loss: 0.6014, Training Accuracy: 82.19%\n",
      "Epoch 18, Batch 60/103, Loss: 0.5908, Training Accuracy: 82.34%\n",
      "Epoch 18, Batch 70/103, Loss: 0.5394, Training Accuracy: 82.63%\n",
      "Epoch 18, Batch 80/103, Loss: 0.6160, Training Accuracy: 82.34%\n",
      "Epoch 18, Batch 90/103, Loss: 0.6030, Training Accuracy: 82.33%\n",
      "Epoch 18, Batch 100/103, Loss: 0.5712, Training Accuracy: 82.31%\n",
      "Epoch 18, Training Accuracy: 82.33%, Validation Accuracy: 82.31%\n",
      "Epoch 19, Batch 10/103, Loss: 0.5925, Training Accuracy: 81.25%\n",
      "Epoch 19, Batch 20/103, Loss: 0.5476, Training Accuracy: 82.97%\n",
      "Epoch 19, Batch 30/103, Loss: 0.6030, Training Accuracy: 82.60%\n",
      "Epoch 19, Batch 40/103, Loss: 0.5862, Training Accuracy: 82.07%\n",
      "Epoch 19, Batch 50/103, Loss: 0.5579, Training Accuracy: 82.62%\n",
      "Epoch 19, Batch 60/103, Loss: 0.6220, Training Accuracy: 82.27%\n",
      "Epoch 19, Batch 70/103, Loss: 0.5760, Training Accuracy: 82.46%\n",
      "Epoch 19, Batch 80/103, Loss: 0.5636, Training Accuracy: 82.64%\n",
      "Epoch 19, Batch 90/103, Loss: 0.6044, Training Accuracy: 82.48%\n",
      "Epoch 19, Batch 100/103, Loss: 0.5839, Training Accuracy: 82.61%\n",
      "Epoch 19, Training Accuracy: 82.54%, Validation Accuracy: 82.76%\n",
      "Epoch 20, Batch 10/103, Loss: 0.5918, Training Accuracy: 81.88%\n",
      "Epoch 20, Batch 20/103, Loss: 0.5877, Training Accuracy: 81.80%\n",
      "Epoch 20, Batch 30/103, Loss: 0.6054, Training Accuracy: 81.25%\n",
      "Epoch 20, Batch 40/103, Loss: 0.5873, Training Accuracy: 81.56%\n",
      "Epoch 20, Batch 50/103, Loss: 0.5779, Training Accuracy: 81.78%\n",
      "Epoch 20, Batch 60/103, Loss: 0.5916, Training Accuracy: 81.95%\n",
      "Epoch 20, Batch 70/103, Loss: 0.5892, Training Accuracy: 81.92%\n",
      "Epoch 20, Batch 80/103, Loss: 0.5508, Training Accuracy: 82.30%\n",
      "Epoch 20, Batch 90/103, Loss: 0.5554, Training Accuracy: 82.57%\n",
      "Epoch 20, Batch 100/103, Loss: 0.6009, Training Accuracy: 82.45%\n",
      "Epoch 20, Training Accuracy: 82.54%, Validation Accuracy: 82.76%\n",
      "Test Accuracy: 75.64%\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        if batch_idx % 10 == 9:  # Print every 10 batches\n",
    "            print(f\"Epoch {epoch+1}, Batch {batch_idx+1}/{len(train_loader)}, Loss: {running_loss / 10:.4f}, Training Accuracy: {100 * correct / total:.2f}%\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # Validation accuracy calculation\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for val_inputs, val_labels in val_loader:\n",
    "            val_outputs = model(val_inputs)\n",
    "            _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "            val_total += val_labels.size(0)\n",
    "            val_correct += (val_predicted == val_labels).sum().item()\n",
    "\n",
    "    val_accuracy = 100 * val_correct / val_total\n",
    "    print(f\"Epoch {epoch+1}, Training Accuracy: {100 * correct / total:.2f}%, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "# Evaluation on the test set\n",
    "model.eval()\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test_inputs, test_labels in test_loader:\n",
    "        test_outputs = model(test_inputs)\n",
    "        _, test_predicted = torch.max(test_outputs.data, 1)\n",
    "        test_total += test_labels.size(0)\n",
    "        test_correct += (test_predicted == test_labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * test_correct / test_total:.2f}%\")\n",
    "torch.save(model.state_dict(), 'ViT_RGB_pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
